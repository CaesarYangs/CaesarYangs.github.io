<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>O3-内存管理 | Caesar's Paperbox</title><meta name=keywords content="Learning,Notes,OS"><meta name=description content="Intro 内存管理包括内存管理概念、交换与覆盖、连续分配管理方式和非连续分配管理方式（分页管理方式、分段管理方式、段页式管理方式）。
虚拟内存管理包括虚拟内存概念、请求分页管理方式、页面置换算法、页面分配策略、工作集和抖动。
3.内存管理 （1）内存管理基础 1）内存管理概念 ：程序装入与链接，逻辑地址与物理地址空间，内存保护 2）交换与覆盖 3）连续分配管理方式 4）非连续分配管理方式 ：分页管理方式，分段管理方式，段页式管理方式 （2）虚拟内存管理 1）虚拟内存基本概念 2）请求分页管理方式 3）页面置换算法 ：最佳置换算法（OPT），先进先出置换算法（FIFO），最近最少使用置换算法（LRU），时钟置换算法（CLOCK） 4）页面分配策略 5）工作集 6）抖动 1 内存管理概念 内存管理(Memory Management)是操作系统设计中最重要和最复杂的内容之一。
虽然计算机硬件一直在飞速发展，内存容量也在不断增长，但是仍然不可能将所有用户进程和系统所需要的全部程序和数据放入主存中，所以操作系统必须将内存空间进行合理地划分和有效地动态分配。操作系统对内存的划分和动态分配，就是内存管理的概念。
有效的内存管理在多道程序设计中非常重要，不仅方便用户使用存储器、提高内存利用率，还可以通过虚拟技术从逻辑上扩充存储器。
内存管理的功能： 内存空间的分配与回收：由操作系统完成主存储器空间的分配和管理，使程序员摆脱存储分配的麻烦，提高编程效率。 地址转换：在多道程序环境下，程序中的逻辑地址与内存中的物理地址不可能一致，因此存储管理必须提供地址变换功能，把逻辑地址转换成相应的物理地址。 内存空间的扩充：利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存。 存储保护：保证各道作业在各自的存储空间内运行，互不干扰。 程序装入与链接 创建进程首先要将程序和数据装入内存。
将用户源程序变为可在内存中执行的程序，通常需要以下几个步骤： 编译：由编译程序将用户源代码编译成若干个目标模块。 链接：由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块。 装入：由装入程序将装入模块装入内存运行。 程序链接方式：
静态链接： 在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，以后不再拆开。 装入时动态链接： 将用户源程序编译后所得到的一组目标模块，在装入内存时，釆用边装入边链接的链接方式。 运行时动态链接： 对某些目标模块的链接，是在程序执行中需要该目标模块时，才对它进行的链接。其优点是便于修改和更新，便于实现对目标模块的共享。 内存的装入模块在装入内存时，同样有以下三种方式：
绝对装入 在编译时，如果知道程序将驻留在内存的某个位置，编译程序将产生绝对地址的目标代码。绝对装入程序按照装入模块中的地址，将程序和数据装入内存。由于程序中的逻辑地址与实际内存地址完全相同，故不需对程序和数据的地址进行修改。 绝对装入方式只适用于单道程序环境。另外，程序中所使用的绝对地址,可在编译或汇编时给出，也可由程序员直接赋予。而通常情况下在程序中釆用的是符号地址，编译或汇编时再转换为绝对地址。 可重定位装入——静态重定位 在作业运行前一次性装入分配全部所需的内存空间 在多道程序环境下，多个目标模块的起始地址通常都是从 0 开始，程序中的其他地址都是相对于起始地址的,此时应釆用可重定位装入方式。根据内存的当前情况，将装入模块装入到内存的适当位置。 装入时对目标程序中指令和数据的修改过程称为重定位，地址变换通常是在装入时一次完成的，所以又称为静态重定位。 静态重定位的特点是在一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入该作业。此外，作业一旦进入内存后，在整个运行期间不能在内存中移动，也不能再申请内存空间。 动态运行时装入——动态重定位 动态运行时，实时将所需内存空间分配并装入，且均为相对地址 程序在内存中如果发生移动，就需要釆用动态的装入方式。装入程序在把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正要执行时才进行。因此，装入内存后的所有地址均为相对地址。 这种方式需要一个重定位寄存器的支持 动态重定位的特点是可以将程序分配到不连续的存储区中；在程序运行之前可以只装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。 基址寄存器与界限寄存器
意义：——真正实现了内存地址动态重定位 这个方法利用的就是动态重定位技术。即简单地把每个进程的地址空间映射到物理内存的不同部分。 基址寄存器-即基地址 Reg 存储当前的基地址 界限寄存器 主要提供地址越界检查保护 此时，程序装载到内存中的连续空闲位置且装载期间无需重定位。 程序的起始物理地址装载到基址寄存器 程序的长度装载到界限寄存器 每次一个进程访问内存，取一条指令，读或写一个数据字，CPU 硬件会在把地址发送到内存总线前， 自动把基址值加到进程发出的地址值上。同时，它检查程序提供的地址是否等于或大于界限寄存器里的值。 如果访问的地址超过了界限，会产生错误并中止访问。 Q：如何实现动态地址重定位？"><meta name=author content="CaesarYang"><link rel=canonical href=/post/tech/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/o3-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.d0947ecfa67e4e172f8a6c5415fa13349ff99ea5ebe6949dcdd38ab29bb25783.css integrity="sha256-0JR+z6Z+ThcvimxUFfoTNJ/5nqXr5pSdzdOKspuyV4M=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=//cdn.jsdelivr.net/npm/hack-font@3.3.0/build/web/hack.css><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="O3-内存管理"><meta property="og:description" content="Intro 内存管理包括内存管理概念、交换与覆盖、连续分配管理方式和非连续分配管理方式（分页管理方式、分段管理方式、段页式管理方式）。
虚拟内存管理包括虚拟内存概念、请求分页管理方式、页面置换算法、页面分配策略、工作集和抖动。
3.内存管理 （1）内存管理基础 1）内存管理概念 ：程序装入与链接，逻辑地址与物理地址空间，内存保护 2）交换与覆盖 3）连续分配管理方式 4）非连续分配管理方式 ：分页管理方式，分段管理方式，段页式管理方式 （2）虚拟内存管理 1）虚拟内存基本概念 2）请求分页管理方式 3）页面置换算法 ：最佳置换算法（OPT），先进先出置换算法（FIFO），最近最少使用置换算法（LRU），时钟置换算法（CLOCK） 4）页面分配策略 5）工作集 6）抖动 1 内存管理概念 内存管理(Memory Management)是操作系统设计中最重要和最复杂的内容之一。
虽然计算机硬件一直在飞速发展，内存容量也在不断增长，但是仍然不可能将所有用户进程和系统所需要的全部程序和数据放入主存中，所以操作系统必须将内存空间进行合理地划分和有效地动态分配。操作系统对内存的划分和动态分配，就是内存管理的概念。
有效的内存管理在多道程序设计中非常重要，不仅方便用户使用存储器、提高内存利用率，还可以通过虚拟技术从逻辑上扩充存储器。
内存管理的功能： 内存空间的分配与回收：由操作系统完成主存储器空间的分配和管理，使程序员摆脱存储分配的麻烦，提高编程效率。 地址转换：在多道程序环境下，程序中的逻辑地址与内存中的物理地址不可能一致，因此存储管理必须提供地址变换功能，把逻辑地址转换成相应的物理地址。 内存空间的扩充：利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存。 存储保护：保证各道作业在各自的存储空间内运行，互不干扰。 程序装入与链接 创建进程首先要将程序和数据装入内存。
将用户源程序变为可在内存中执行的程序，通常需要以下几个步骤： 编译：由编译程序将用户源代码编译成若干个目标模块。 链接：由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块。 装入：由装入程序将装入模块装入内存运行。 程序链接方式：
静态链接： 在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，以后不再拆开。 装入时动态链接： 将用户源程序编译后所得到的一组目标模块，在装入内存时，釆用边装入边链接的链接方式。 运行时动态链接： 对某些目标模块的链接，是在程序执行中需要该目标模块时，才对它进行的链接。其优点是便于修改和更新，便于实现对目标模块的共享。 内存的装入模块在装入内存时，同样有以下三种方式：
绝对装入 在编译时，如果知道程序将驻留在内存的某个位置，编译程序将产生绝对地址的目标代码。绝对装入程序按照装入模块中的地址，将程序和数据装入内存。由于程序中的逻辑地址与实际内存地址完全相同，故不需对程序和数据的地址进行修改。 绝对装入方式只适用于单道程序环境。另外，程序中所使用的绝对地址,可在编译或汇编时给出，也可由程序员直接赋予。而通常情况下在程序中釆用的是符号地址，编译或汇编时再转换为绝对地址。 可重定位装入——静态重定位 在作业运行前一次性装入分配全部所需的内存空间 在多道程序环境下，多个目标模块的起始地址通常都是从 0 开始，程序中的其他地址都是相对于起始地址的,此时应釆用可重定位装入方式。根据内存的当前情况，将装入模块装入到内存的适当位置。 装入时对目标程序中指令和数据的修改过程称为重定位，地址变换通常是在装入时一次完成的，所以又称为静态重定位。 静态重定位的特点是在一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入该作业。此外，作业一旦进入内存后，在整个运行期间不能在内存中移动，也不能再申请内存空间。 动态运行时装入——动态重定位 动态运行时，实时将所需内存空间分配并装入，且均为相对地址 程序在内存中如果发生移动，就需要釆用动态的装入方式。装入程序在把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正要执行时才进行。因此，装入内存后的所有地址均为相对地址。 这种方式需要一个重定位寄存器的支持 动态重定位的特点是可以将程序分配到不连续的存储区中；在程序运行之前可以只装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。 基址寄存器与界限寄存器
意义：——真正实现了内存地址动态重定位 这个方法利用的就是动态重定位技术。即简单地把每个进程的地址空间映射到物理内存的不同部分。 基址寄存器-即基地址 Reg 存储当前的基地址 界限寄存器 主要提供地址越界检查保护 此时，程序装载到内存中的连续空闲位置且装载期间无需重定位。 程序的起始物理地址装载到基址寄存器 程序的长度装载到界限寄存器 每次一个进程访问内存，取一条指令，读或写一个数据字，CPU 硬件会在把地址发送到内存总线前， 自动把基址值加到进程发出的地址值上。同时，它检查程序提供的地址是否等于或大于界限寄存器里的值。 如果访问的地址超过了界限，会产生错误并中止访问。 Q：如何实现动态地址重定位？"><meta property="og:type" content="article"><meta property="og:url" content="/post/tech/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/o3-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"><meta property="og:image" content="/avatar.jpeg"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-05-04T11:40:58+08:00"><meta property="article:modified_time" content="2022-05-04T11:40:58+08:00"><meta property="og:site_name" content="Caesars Paperbox"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="/avatar.jpeg"><meta name=twitter:title content="O3-内存管理"><meta name=twitter:description content="Intro 内存管理包括内存管理概念、交换与覆盖、连续分配管理方式和非连续分配管理方式（分页管理方式、分段管理方式、段页式管理方式）。
虚拟内存管理包括虚拟内存概念、请求分页管理方式、页面置换算法、页面分配策略、工作集和抖动。
3.内存管理 （1）内存管理基础 1）内存管理概念 ：程序装入与链接，逻辑地址与物理地址空间，内存保护 2）交换与覆盖 3）连续分配管理方式 4）非连续分配管理方式 ：分页管理方式，分段管理方式，段页式管理方式 （2）虚拟内存管理 1）虚拟内存基本概念 2）请求分页管理方式 3）页面置换算法 ：最佳置换算法（OPT），先进先出置换算法（FIFO），最近最少使用置换算法（LRU），时钟置换算法（CLOCK） 4）页面分配策略 5）工作集 6）抖动 1 内存管理概念 内存管理(Memory Management)是操作系统设计中最重要和最复杂的内容之一。
虽然计算机硬件一直在飞速发展，内存容量也在不断增长，但是仍然不可能将所有用户进程和系统所需要的全部程序和数据放入主存中，所以操作系统必须将内存空间进行合理地划分和有效地动态分配。操作系统对内存的划分和动态分配，就是内存管理的概念。
有效的内存管理在多道程序设计中非常重要，不仅方便用户使用存储器、提高内存利用率，还可以通过虚拟技术从逻辑上扩充存储器。
内存管理的功能： 内存空间的分配与回收：由操作系统完成主存储器空间的分配和管理，使程序员摆脱存储分配的麻烦，提高编程效率。 地址转换：在多道程序环境下，程序中的逻辑地址与内存中的物理地址不可能一致，因此存储管理必须提供地址变换功能，把逻辑地址转换成相应的物理地址。 内存空间的扩充：利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存。 存储保护：保证各道作业在各自的存储空间内运行，互不干扰。 程序装入与链接 创建进程首先要将程序和数据装入内存。
将用户源程序变为可在内存中执行的程序，通常需要以下几个步骤： 编译：由编译程序将用户源代码编译成若干个目标模块。 链接：由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块。 装入：由装入程序将装入模块装入内存运行。 程序链接方式：
静态链接： 在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，以后不再拆开。 装入时动态链接： 将用户源程序编译后所得到的一组目标模块，在装入内存时，釆用边装入边链接的链接方式。 运行时动态链接： 对某些目标模块的链接，是在程序执行中需要该目标模块时，才对它进行的链接。其优点是便于修改和更新，便于实现对目标模块的共享。 内存的装入模块在装入内存时，同样有以下三种方式：
绝对装入 在编译时，如果知道程序将驻留在内存的某个位置，编译程序将产生绝对地址的目标代码。绝对装入程序按照装入模块中的地址，将程序和数据装入内存。由于程序中的逻辑地址与实际内存地址完全相同，故不需对程序和数据的地址进行修改。 绝对装入方式只适用于单道程序环境。另外，程序中所使用的绝对地址,可在编译或汇编时给出，也可由程序员直接赋予。而通常情况下在程序中釆用的是符号地址，编译或汇编时再转换为绝对地址。 可重定位装入——静态重定位 在作业运行前一次性装入分配全部所需的内存空间 在多道程序环境下，多个目标模块的起始地址通常都是从 0 开始，程序中的其他地址都是相对于起始地址的,此时应釆用可重定位装入方式。根据内存的当前情况，将装入模块装入到内存的适当位置。 装入时对目标程序中指令和数据的修改过程称为重定位，地址变换通常是在装入时一次完成的，所以又称为静态重定位。 静态重定位的特点是在一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入该作业。此外，作业一旦进入内存后，在整个运行期间不能在内存中移动，也不能再申请内存空间。 动态运行时装入——动态重定位 动态运行时，实时将所需内存空间分配并装入，且均为相对地址 程序在内存中如果发生移动，就需要釆用动态的装入方式。装入程序在把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正要执行时才进行。因此，装入内存后的所有地址均为相对地址。 这种方式需要一个重定位寄存器的支持 动态重定位的特点是可以将程序分配到不连续的存储区中；在程序运行之前可以只装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。 基址寄存器与界限寄存器
意义：——真正实现了内存地址动态重定位 这个方法利用的就是动态重定位技术。即简单地把每个进程的地址空间映射到物理内存的不同部分。 基址寄存器-即基地址 Reg 存储当前的基地址 界限寄存器 主要提供地址越界检查保护 此时，程序装载到内存中的连续空闲位置且装载期间无需重定位。 程序的起始物理地址装载到基址寄存器 程序的长度装载到界限寄存器 每次一个进程访问内存，取一条指令，读或写一个数据字，CPU 硬件会在把地址发送到内存总线前， 自动把基址值加到进程发出的地址值上。同时，它检查程序提供的地址是否等于或大于界限寄存器里的值。 如果访问的地址超过了界限，会产生错误并中止访问。 Q：如何实现动态地址重定位？"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Articles","item":"/post/"},{"@type":"ListItem","position":3,"name":"Tech","item":"/post/tech/"},{"@type":"ListItem","position":5,"name":"O3-内存管理","item":"/post/tech/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/o3-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"O3-内存管理","name":"O3-内存管理","description":"Intro 内存管理包括内存管理概念、交换与覆盖、连续分配管理方式和非连续分配管理方式（分页管理方式、分段管理方式、段页式管理方式）。\n虚拟内存管理包括虚拟内存概念、请求分页管理方式、页面置换算法、页面分配策略、工作集和抖动。\n3.内存管理 （1）内存管理基础 1）内存管理概念 ：程序装入与链接，逻辑地址与物理地址空间，内存保护 2）交换与覆盖 3）连续分配管理方式 4）非连续分配管理方式 ：分页管理方式，分段管理方式，段页式管理方式 （2）虚拟内存管理 1）虚拟内存基本概念 2）请求分页管理方式 3）页面置换算法 ：最佳置换算法（OPT），先进先出置换算法（FIFO），最近最少使用置换算法（LRU），时钟置换算法（CLOCK） 4）页面分配策略 5）工作集 6）抖动 1 内存管理概念 内存管理(Memory Management)是操作系统设计中最重要和最复杂的内容之一。\n虽然计算机硬件一直在飞速发展，内存容量也在不断增长，但是仍然不可能将所有用户进程和系统所需要的全部程序和数据放入主存中，所以操作系统必须将内存空间进行合理地划分和有效地动态分配。操作系统对内存的划分和动态分配，就是内存管理的概念。\n有效的内存管理在多道程序设计中非常重要，不仅方便用户使用存储器、提高内存利用率，还可以通过虚拟技术从逻辑上扩充存储器。\n内存管理的功能： 内存空间的分配与回收：由操作系统完成主存储器空间的分配和管理，使程序员摆脱存储分配的麻烦，提高编程效率。 地址转换：在多道程序环境下，程序中的逻辑地址与内存中的物理地址不可能一致，因此存储管理必须提供地址变换功能，把逻辑地址转换成相应的物理地址。 内存空间的扩充：利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存。 存储保护：保证各道作业在各自的存储空间内运行，互不干扰。 程序装入与链接 创建进程首先要将程序和数据装入内存。\n将用户源程序变为可在内存中执行的程序，通常需要以下几个步骤： 编译：由编译程序将用户源代码编译成若干个目标模块。 链接：由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块。 装入：由装入程序将装入模块装入内存运行。 程序链接方式：\n静态链接： 在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，以后不再拆开。 装入时动态链接： 将用户源程序编译后所得到的一组目标模块，在装入内存时，釆用边装入边链接的链接方式。 运行时动态链接： 对某些目标模块的链接，是在程序执行中需要该目标模块时，才对它进行的链接。其优点是便于修改和更新，便于实现对目标模块的共享。 内存的装入模块在装入内存时，同样有以下三种方式：\n绝对装入 在编译时，如果知道程序将驻留在内存的某个位置，编译程序将产生绝对地址的目标代码。绝对装入程序按照装入模块中的地址，将程序和数据装入内存。由于程序中的逻辑地址与实际内存地址完全相同，故不需对程序和数据的地址进行修改。 绝对装入方式只适用于单道程序环境。另外，程序中所使用的绝对地址,可在编译或汇编时给出，也可由程序员直接赋予。而通常情况下在程序中釆用的是符号地址，编译或汇编时再转换为绝对地址。 可重定位装入——静态重定位 在作业运行前一次性装入分配全部所需的内存空间 在多道程序环境下，多个目标模块的起始地址通常都是从 0 开始，程序中的其他地址都是相对于起始地址的,此时应釆用可重定位装入方式。根据内存的当前情况，将装入模块装入到内存的适当位置。 装入时对目标程序中指令和数据的修改过程称为重定位，地址变换通常是在装入时一次完成的，所以又称为静态重定位。 静态重定位的特点是在一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入该作业。此外，作业一旦进入内存后，在整个运行期间不能在内存中移动，也不能再申请内存空间。 动态运行时装入——动态重定位 动态运行时，实时将所需内存空间分配并装入，且均为相对地址 程序在内存中如果发生移动，就需要釆用动态的装入方式。装入程序在把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正要执行时才进行。因此，装入内存后的所有地址均为相对地址。 这种方式需要一个重定位寄存器的支持 动态重定位的特点是可以将程序分配到不连续的存储区中；在程序运行之前可以只装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。 基址寄存器与界限寄存器\n意义：——真正实现了内存地址动态重定位 这个方法利用的就是动态重定位技术。即简单地把每个进程的地址空间映射到物理内存的不同部分。 基址寄存器-即基地址 Reg 存储当前的基地址 界限寄存器 主要提供地址越界检查保护 此时，程序装载到内存中的连续空闲位置且装载期间无需重定位。 程序的起始物理地址装载到基址寄存器 程序的长度装载到界限寄存器 每次一个进程访问内存，取一条指令，读或写一个数据字，CPU 硬件会在把地址发送到内存总线前， 自动把基址值加到进程发出的地址值上。同时，它检查程序提供的地址是否等于或大于界限寄存器里的值。 如果访问的地址超过了界限，会产生错误并中止访问。 Q：如何实现动态地址重定位？","keywords":["Learning","Notes","OS"],"articleBody":"Intro 内存管理包括内存管理概念、交换与覆盖、连续分配管理方式和非连续分配管理方式（分页管理方式、分段管理方式、段页式管理方式）。\n虚拟内存管理包括虚拟内存概念、请求分页管理方式、页面置换算法、页面分配策略、工作集和抖动。\n3.内存管理 （1）内存管理基础 1）内存管理概念 ：程序装入与链接，逻辑地址与物理地址空间，内存保护 2）交换与覆盖 3）连续分配管理方式 4）非连续分配管理方式 ：分页管理方式，分段管理方式，段页式管理方式 （2）虚拟内存管理 1）虚拟内存基本概念 2）请求分页管理方式 3）页面置换算法 ：最佳置换算法（OPT），先进先出置换算法（FIFO），最近最少使用置换算法（LRU），时钟置换算法（CLOCK） 4）页面分配策略 5）工作集 6）抖动 1 内存管理概念 内存管理(Memory Management)是操作系统设计中最重要和最复杂的内容之一。\n虽然计算机硬件一直在飞速发展，内存容量也在不断增长，但是仍然不可能将所有用户进程和系统所需要的全部程序和数据放入主存中，所以操作系统必须将内存空间进行合理地划分和有效地动态分配。操作系统对内存的划分和动态分配，就是内存管理的概念。\n有效的内存管理在多道程序设计中非常重要，不仅方便用户使用存储器、提高内存利用率，还可以通过虚拟技术从逻辑上扩充存储器。\n内存管理的功能： 内存空间的分配与回收：由操作系统完成主存储器空间的分配和管理，使程序员摆脱存储分配的麻烦，提高编程效率。 地址转换：在多道程序环境下，程序中的逻辑地址与内存中的物理地址不可能一致，因此存储管理必须提供地址变换功能，把逻辑地址转换成相应的物理地址。 内存空间的扩充：利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存。 存储保护：保证各道作业在各自的存储空间内运行，互不干扰。 程序装入与链接 创建进程首先要将程序和数据装入内存。\n将用户源程序变为可在内存中执行的程序，通常需要以下几个步骤： 编译：由编译程序将用户源代码编译成若干个目标模块。 链接：由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块。 装入：由装入程序将装入模块装入内存运行。 程序链接方式：\n静态链接： 在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，以后不再拆开。 装入时动态链接： 将用户源程序编译后所得到的一组目标模块，在装入内存时，釆用边装入边链接的链接方式。 运行时动态链接： 对某些目标模块的链接，是在程序执行中需要该目标模块时，才对它进行的链接。其优点是便于修改和更新，便于实现对目标模块的共享。 内存的装入模块在装入内存时，同样有以下三种方式：\n绝对装入 在编译时，如果知道程序将驻留在内存的某个位置，编译程序将产生绝对地址的目标代码。绝对装入程序按照装入模块中的地址，将程序和数据装入内存。由于程序中的逻辑地址与实际内存地址完全相同，故不需对程序和数据的地址进行修改。 绝对装入方式只适用于单道程序环境。另外，程序中所使用的绝对地址,可在编译或汇编时给出，也可由程序员直接赋予。而通常情况下在程序中釆用的是符号地址，编译或汇编时再转换为绝对地址。 可重定位装入——静态重定位 在作业运行前一次性装入分配全部所需的内存空间 在多道程序环境下，多个目标模块的起始地址通常都是从 0 开始，程序中的其他地址都是相对于起始地址的,此时应釆用可重定位装入方式。根据内存的当前情况，将装入模块装入到内存的适当位置。 装入时对目标程序中指令和数据的修改过程称为重定位，地址变换通常是在装入时一次完成的，所以又称为静态重定位。 静态重定位的特点是在一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入该作业。此外，作业一旦进入内存后，在整个运行期间不能在内存中移动，也不能再申请内存空间。 动态运行时装入——动态重定位 动态运行时，实时将所需内存空间分配并装入，且均为相对地址 程序在内存中如果发生移动，就需要釆用动态的装入方式。装入程序在把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正要执行时才进行。因此，装入内存后的所有地址均为相对地址。 这种方式需要一个重定位寄存器的支持 动态重定位的特点是可以将程序分配到不连续的存储区中；在程序运行之前可以只装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。 基址寄存器与界限寄存器\n意义：——真正实现了内存地址动态重定位 这个方法利用的就是动态重定位技术。即简单地把每个进程的地址空间映射到物理内存的不同部分。 基址寄存器-即基地址 Reg 存储当前的基地址 界限寄存器 主要提供地址越界检查保护 此时，程序装载到内存中的连续空闲位置且装载期间无需重定位。 程序的起始物理地址装载到基址寄存器 程序的长度装载到界限寄存器 每次一个进程访问内存，取一条指令，读或写一个数据字，CPU 硬件会在把地址发送到内存总线前， 自动把基址值加到进程发出的地址值上。同时，它检查程序提供的地址是否等于或大于界限寄存器里的值。 如果访问的地址超过了界限，会产生错误并中止访问。 Q：如何实现动态地址重定位？\n因为每个内存地址在送到内存之前,都会自动先加上基址寄存器的内容。 且在很多实际系统中,对基址寄存器和界限寄存器会以一定的方式加以保护,使得只有操作系统可以修改它们。 动态地址重定位\n在程序执行过程中，CPU 访存前，将要访问的程序或数据地址转换为内存地址。动态地址重定位依靠硬件地址变换机构完成。 具体实现：地址重定位机构 m 个基地址寄存器 BR+n 个程序虚拟地址寄存器 VR=\u003e共同构成指令或数据的内存地址 MA 优点： 对内存进行连续分配 是实现虚存的基础 利于程序段共享 $$MA = (BR) + (VR)$$\n逻辑地址空间与物理地址空间 逻辑地址\n编译后，每个目标模块都是从 0 号单元开始编址，称为该目标模块的相对地址（或逻辑地址)。 当链接程序将各个模块链接成一个完整的可执行目标程序时，链接程序顺序依次按各个模块的相对地址构成统一的从 0 号单元开始编址的逻辑地址空间。用户程序和程序员只需知道逻辑地址，而内存管理的具体机制则是完全透明的，它们只有系统编程人员才会涉及。不同进程可以有相同的逻辑地址，因为这些相同的逻辑地址可以映射到主存的不同位置。 物理地址\n物理地址空间是指内存中物理单元的集合，它是地址转换的最终地址，进程在运行时执行指令和访问数据最后都要通过物理地址从主存中存取。 当装入程序将可执行代码装入内存时，必须通过地址转换将逻辑地址转换成物理地址，这个过程称为地址重定位。 基址+界限寄存器的缺点：\n每次访存都需要进行加法和比较运算 比较运算可以很快；但加法运算由于进位传递时间的问题，在没有特殊电路的情况下会比较慢。 内存保护 内存分配前，需要保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。\n通过釆用重定位寄存器（基址寄存器）和界地址寄存器（界限寄存器）来实现这种保护。 重定位寄存器含最小的物理地址值，界地址寄存器含逻辑地址值。 每个逻辑地址值必须小于界地址寄存器； 内存管理机构动态地将逻辑地址与界地址寄存器进行比较，如果未发生地址越界，则加上重定位寄存器的值后映射成物理地址，再送交内存单元。 当 CPU 调度程序选择进程执行时，派遣程序会初始化重定位寄存器和界地址寄存器。每一个逻辑地址都需要与这两个寄存器进行核对，以保证操作系统和其他用户程序及数据不被该进程的运行所影响。 整个系统中只有一个基地址寄存器（重定位寄存器）和一个界限寄存器（界地址寄存器） 基址寄存器和界限寄存器完全实现了动态地址重定位+内存地址保护的所有功能\n覆盖与交换 覆盖与交换技术是在多道程序环境下用来扩充内存的两种方法。\n覆盖 早期的计算机系统中，主存容量很小，虽然主存中仅存放一道用户程序，但是存储空间放不下用户进程的现象也经常发生，这一矛盾可以用覆盖技术来解决。\n早期内存扩充技术。用户需指定好各程序调入 memory 的先后次序。 覆盖的基本思想： 由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序），因此可以把用户空间分成一个固定区和若干个覆盖区。 将经常活跃的部分放在固定区，其余部分按调用关系分段。首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。 覆盖技术的特点是打破了必须将一个进程的全部信息装入主存后才能运行的限制，但当同时运行程序的代码量大于主存时仍不能运行。\n交换 将内存等待状态进程换出内存；将处于外存就绪态进程换入内存。 交换的基本思想： 把处于等待状态（或在 CPU 调度原则下被剥夺运行权利） 的程序从内存移到辅存，把内存空间腾出来，这一过程又叫换出； 把准备好竞争 CPU 运行的程序从辅存移到内存，这一过程又称为换入。[[2 进程管理#中级调度]]就是釆用交换技术。 e.g. 有一个 CPU 釆用时间片轮转调度算法的多道程序环境。时间片到，内存管理器将刚刚执行过的进程换出，将另一进程换入到刚刚释放的内存空间中。同时，CPU 调度器可以将时间片分配给其他已在内存中的进程。每个进程用完时间片都与另一进程交换。 理想情况下，内存管理器的交换过程速度足够快，总有进程在内存中可以执行。\n有关交换需要注意以下几个问题： 交换需要备份存储，通常是快速磁盘。它必须足够大，并且提供对这些内存映像的直接访问。 为了有效使用 CPU，需要每个进程的执行时间比交换时间长，而影响交换时间的主要是转移时间。转移时间与所交换的内存空间成正比。 如果换出进程，必须确保该进程是完全处于空闲状态。 交换空间通常作为磁盘的一整块，且独立于文件系统，因此使用就可能很快。 交换通常在有许多进程运行且内存空间吃紧时开始启动，而系统负荷降低就暂停。 普通的交换使用不多，但交换策略的某些变种在许多系统中（如 UNIX 系统）仍发挥作用。 交换技术主要是在不同进程（或作业）之间进行，而覆盖则用于同一个程序或进程中。\n只有请求调入和预调入能够实现大小不受内存容量限制的虚存\nQ：在这种情况下交换为什么不能实现虚存？\n交换不进行部分程序段或数据段的交换，其会交换整个进程。并且完成的部分交换也只是将受资源限制，暂时不能执行的程序段换出内存。 因此，虽然交换方式也能完成内存扩充任务，但无法实现自动覆盖，内外存统一管理。 即：虚存的本质意义在于 seamless 让用户和进程无感切换内外存。\n由于覆盖技术要求给出程序段之间的覆盖结构，使得其对用户和程序员不透明，所以对于主存无法存放用户程序的矛盾，现代操作系统是通过虚拟内存技术来解决的，覆盖技术则已成为历史；而交换技术在现代操作系统中仍具有较强的生命力。\n内存连续分配管理 连续分配方式，是指为一个用户程序分配一个连续的内存空间。 它主要包括单一连续分配、固定分区分配和动态分区分配。\n进程是操作系统资源分配的最小单元。操作系统分配给进程的内存空间中包含五种段：数据段、代码段、BSS、堆、栈。\n数据段：\n存放程序中的静态变量 已初始化且不为零的全局变量。 代码段：\n存放可执行文件的操作指令，代码段是只读的，不可进行写操作。这部分的区域在运行前已知其大小。 BSS 段( Block Started By Symbol)：\n存放未初始化的全局变量。在变量使用前由运行时初始化为零。 堆：\n存放进程运行中被动态分配的内存，其大小不固定。 栈：\n存放程序中的临时的局部变量 函数的参数值。 这就是为什么局部变量和全局变量有着本质区别的原因 局部变量作为临时信息存放在当前运行程序的栈中；全局变量则放置在数据段中。 由于运行过程中所产生的用户申请空间不固定，所以必须放在堆中：即可以随时方便扩容 高频面试题——你真的搞懂物理内存与虚拟内存了吗 - 腾讯云开发者社区-腾讯云\n单一连续分配 内存在此方式下分为系统区和用户区，系统区仅提供给操作系统使用，通常在低地址部分；用户区是为用户提供的、除系统区之外的内存空间。 这种方式无需进行内存保护。 优缺点分析： 这种方式的优点是简单、无外部碎片，可以釆用覆盖技术，不需要额外的技术支持。 缺点是只能用于单用户、单任务的操作系统中，有内部碎片，存储器的利用率极低。 固定分区分配 固定分区分配是最简单的一种多道程序存储管理方式，它将用户内存空间划分为若干个固定大小的区域，每个分区只装入一道作业。当有空闲分区时，便可以再从外存的后备作业队列中,选择适当大小的作业装入该分区，如此循环。\n固定分区分配在划分分区时，有两种不同的方法。 ^a8d988\n分区大小相等：用于利用一台计算机去控制多个相同对象的场合，缺乏灵活性。 分区大小不等：划分为含有多个较小的分区、适量的中等分区及少量的大分区。 为便于内存分配，通常将分区按大小排队，并为之建立一张分区说明表，其中各表项包括每个分区的起始地址、大小及状态（是否已分配）。当有用户程序要装入时，便检索该表，以找到合适的分区给予分配并将其状态置为”已分配”；未找到合适分区则拒绝为该用户程序分配内存。存储空间的分配情况。\n分区说明表\nOS 对内存的管理和控制通过分区说明表实现。 分区号、分区大小、起始地址和分区状态（是否空闲区）。 内存的分配实发、存储保护及地址变换都通过分区说明表实现。\n这种分区方式存在两个问题：\n一是程序可能太大而放不进任何一个分区中，这时用户不得不使用覆盖技术来使用内存空间； 二是主存利用率低，当程序小于固定分区大小时，也占用了一个完整的内存分区空间，这样分区内部有空间浪费，这种现象称为内部碎片。 固定分区产生的是内部碎片。因为整体内存区域已经被完全分配完成，只有在每一个分配块的内部才会出现无法被利用的内容 [[#小结|碎片部分整理]] 优缺点分析：\n优点：可用于多道程序设计的最简单存储分配。设计简单；无外部碎片 缺点：内存利用率低，即使是小作业也要占用相同大小的分区；无法实现内存共享 固定分区分配很少用于现在通用的操作系统中，但在某些用于控制多个相同对象的控制系统中仍发挥着一定的作用。\n动态分区分配 作业执行前不建立分区，分区的建立是在作业的处理过程中进行的。其大小可随作业或进程对内存的要求而改变。\n动态分区分配又称为可变分区分配，是一种动态划分内存的分区方法。 这种分区方法不预先将内存划分，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此系统中分区的大小和数目是可变的。 如图3-6所示，系统有64MB内存空间，其中低8MB固定分配给操作系统，其余为用户可用内存。开始时装入前三个进程，在它们分别分配到所需空间后，内存只剩下4MB，进程4无法装入。在某个时刻，内存中没有一个就绪进程，CPU出现空闲，操作系统就换出进程2，换入进程4。由于进程4比进程2小，这样在主存中就产生了一个6MB的内存块。之后CPU又出现空闲，而主存无法容纳进程2,操作系统就换出进程1，换入进程2。 Q：如何进一步划分不合适的内存空闲区大小？\n如果分配的空闲区比所要求的大，则管理程序将该空闲区分成两个部分，其中一部分成为已分配区，而另一部分成为一个新的小空闲区。 出现相应的内存分区管理：合并 拆分\n最先适应算法 最佳适应算法 最坏适应算法 临近适应算法 动态分区算法会产生外部碎片。主要是由于每个可变的数据块之间是存在可以利用的部分的，通过一定的算法就可以进行外部碎片的重复利用。\n动态分区在开始分配时是很好的，但是之后会导致内存中出现许多小的内存块。随着时间的推移，内存中会产生越来越多的碎片（图 3-6 中最后的 4MB 和中间的 6MB，且随着进程的换入/换出，很可能会出现更多更小的内存块)，内存的利用率随之下降。 ^38dde4\n这些小的内存块称为外部碎片，指在所有分区外的存储空间会变成越来越多的碎片，这与[[3 内存管理#固定分区分配|固定分区]]中的内部碎片正好相对。\n克服外部碎片可以通过紧凑（Compaction)技术来解决，就是操作系统不时地对进程进行移动和整理。\n但是这需要动态重定位寄存器的支持，且相对费时。 紧凑的过程实际上类似于 Windows 系统中的磁盘整理程序，只不过后者是对外存空间的紧凑。 内存紧缩\n交换在内存中产生了多个空闲区(hole,也称为空洞),通过把所有的进程尽可能向下移动,有可能将这些小的空闲区合成一大块。 通常不会进行这个操作，因为其要消耗大量 CPU 时间 Q：在交换时分配内存的大小是否固定？\n若是固定的情况，则分配很简单，只需进行精准分配即可。——即[[#固定分区分配|固定分区]] 但如果进程的数据段可以增长，那么在空间试图增长时，就会出现问题。——即动态分区 一种简单的处理方法是：当换入或移动进程时为其分配一些额外的内存。且当进程被换出到磁盘上时不要计入这部分内容。 在进程装入或换入主存时，如果内存中有多个足够大的空闲块，操作系统必须确定分配哪个内存块给进程使用，这就是动态分区的分配策略\n从可用表或自由链中寻找空闲区的方法：\n首次适应 first fit——快 无需排序 空闲分区以地址递增的次序链接。分配内存时顺序查找，找到大小能满足要求的第一个空闲分区。 首次适配(first fit)算法。存储管理器沿着段链表进行搜索，直到找到一个足够大的空闲区，除非空闲区大小和要分配的空间大小正好一样，否则将该空闲区分为两部分，一部分供进程使用，另一部分形成新的空闲区。 首次适配算法是一种速度很快的算法，因为它尽可能少地搜索链表结点。 最佳适应 best fit——省 低地址充分利用 空闲分区按容量递增形成分区链，找到第一个能满足要求的空闲分区。 最佳适配算法搜索整个链表（从开始到结束)，找出能够容纳进程的最小的空闲区。最佳适配算法试图找出最接近实际需要的空闲区，以最好地匹配请求和可用空闲区，而不是先拆分一个以后可能会用到的大的空闲区。 保证了高地址有较大空间放置对内存要求多的进程或作业。找到最适应，但不一定会增加内存利用率。 实际上其会造成比最佳适应算法更多的内存浪费：因为其会产生大量无用的小空闲区。 最坏适应 worst fit——志在消灭空闲碎片 又称最大适应(Largest Fit)算法，空闲分区以容量递减的次序链接。找到第一个能满足要求的空闲分区，也就是挑选出最大的分区。 找到后划出要求长度，将余下部分合并（如果有相邻空闲存在）留在可用表中。 期望分配后的剩余空间仍能进行再分配。 临近适配 next fit——first fit 的小改进 其工作方式与首次适配算法相同 不同点是每次找到合适的空闲区时都记录当时的位置，以便在下次寻找空闲区时从上次结束的地方开始搜索，而不用每次从头开始 性能略低于 first fit 快速适配 quick fit 其为常用大小的空闲区维护单独的链表 不同方法性能分析\n在这几种方法中，首次适应算法不仅是最简单的，而且通常也是最好和最快的。 在 UNIX 系统的最初版本中，就是使用首次适应算法为进程分配内存空间，其中使用数组的数据结构 (而非链表）来实现。 不过，首次适应算法会使得内存的低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。 邻近适应算法试图解决这个问题 但实际上，它常常会导致在内存的末尾分配空间（因为在一遍扫描中，内存前面部分使用后再释放时，不会参与分配)，分裂成小碎片。 它通常比首次适应算法的结果要差。 最佳适应算法虽然称为“最佳”，但是性能通常很差，因为每次最佳的分配会留下很小的难以利用的内存块，它会产生最多的外部碎片。 最坏适应算法与最佳适应算法相反，选择最大的可用块，这看起来最不容易产生碎片，但是却把最大的连续内存划分开，会很快导致没有可用的大的内存块，因此性能也非常差。 Kunth 和 Shore 分别就前三种方法对内存空间的利用情况做了模拟实验，结果表明：\n首次适应算法可能比最佳适应法效果好，而它们两者一定比最大适应法效果好。 另外注意,在算法实现时,分配操作中最佳适应法和最大适应法需要对可用块进行排序或遍历查找，而首次适应法和邻近适应法只需要简单查找；回收操作中，当回收的块与原来的空闲块相邻时（有三种相邻的情况，比较复杂)，需要将这些块合并。在算法实现时，使用数组或链表进行管理。 除了内存的利用率，这里的算法开销也是操作系统设计需要考虑的一个因素。\n内存的非连续分配管理 非连续分配允许一个程序分散地装入到不相邻的内存分区中，根据分区的大小是否固定分为分页存储管理方式和分段存储管理方式。\n分页存储管理方式中，又根据运行作业时是否要把作业的所有页面都装入内存才能运行分为 基本分页存储管理方式 请求分页存储管理方式。 分页管理 固定分区会产生内部碎片，动态分区会产生外部碎片，这两种技术对内存的利用率都比较低。\n我们希望内存的使用能尽量避免碎片的产生，这就引入了分页的思想：把主存空间划分为大小相等且固定的块，块相对较小，作为主存的基本单位。每个进程也以块为单位进行划分，进程在执行时，以块为单位逐个申请主存中的块空间。\n分页与[[#固定分区分配|固定分区管理]]的异同与联系\n分页的方法从形式上看，像分区相等的固定分区技术，分页管理不会产生外部碎片。 但它又有本质的不同点：块的大小相对分区要小很多，而且进程也按照块进行划分，进程运行时按块申请主存可用空间并执行。 这样，进程只会在为最后一个不完整的块申请一个主存块空间时，才产生主存碎片，所以尽管会产生内部碎片，但是这种碎片相对于进程来说也是很小的，每个进程平均只产生半个块大小的内部碎片（也称页内碎片）。 Q：为什么引入分页技术？\n为了得到大的线性地址空间而不必购买更大的物理存储器 分页 由程序产生的这些地址称为虚拟地址，它们构成了一个虚拟地址空间\n在没有虚存的计算机上，系统直接将虚拟地址送到内存总线上，读写操作使用具有同样地址的物理内存字 在使用虚存的计算机上，虚拟地址不是被直接送到内存总线，而是被送到内存管理单元(Memory Management Unit, MMU) ，MMU 将虚拟地址映射为物理内存地址 虚拟地址空间按照固定大小划分成被称为页面(page) 的若干单元。在物理内存中对应的单元称为页框(pageframe) 。外存也以同样的单位进行划分，直接称为块(Block)。\n页面和页框的大小通常是一样的。但通常也支持不同的页面大小混合使用的原则。 如：若每个单元的大小均为 4KB，则对应于 64KB 的虚拟地址空间和 32KB 的物理内存——可得到 16 个虚拟页面和 8 个页框 程在执行时需要申请主存空间，就是要为每个页面分配主存中的可用页框，这就产生了页和页框的一一对应。 RAM 和磁盘之间的交换总是以整个页面为单元进行的 为方便地址转换，页面大小应是 2 的整数幂。同时页面大小应该适中，如果页面太小，会使进程的页面数过多，这样页表就过长，占用大量内存，而且也会增加硬件地址转换的开销，降低页面换入/换出的效率；页面过大又会使页内碎片增大，降低内存的利用率。所以页面的大小应该适中。 ==用户进程在页面间不再连续。实现了从连续到非连续管理的飞跃。为虚存的真正实现打下了基础。==\n采用请求调页或预调页技术实现内外存统一管理。即实现了虚存 基于工作区的局部性原理建立。 基本的分页+虚拟内存管理模型实例：\nMOV REG,0 将虚拟地址0送到MMU。MMU看到虚拟地址落在页面0(0~4095)，根据其映射结果，这一页面对应的是页框2(8192~12287)，因此MMU把地址变换为8192，并把地址8192送到总线上。内存对MMU一无所知，它只看到一个读或写地址8192的请求并执行它。MMU从而有效地把所有从0~4095的虚拟地址映射到了8192~12287的物理地址。 MOV REG,8192 =====\u003e MOV REG,24576 MOV REG,20500+20 =====\u003e MOV REG,12288+20 通过恰当地设置 MMU，可以将 16 个虚拟页面映射到 8 个页框中的任意一个\nQ：但是这并没有解决虚拟地址空间比物理空间大的问题 此时，拥有 8 个物理页框，也就意味着只能将 8 个存在的虚拟页面映射过去 其他的页面只能用一个 bit 设置 在/不在 位 当程序访问了一个未映射的页面：\nMOV REG,32780 =====\u003e MOV REG,？？？？ 缺页中断 虚拟页面 8（从 32768 开始） 的第 12 个字节所对应的物理地址是什么呢？MMU 注意到该页面没有被映射（在图中用叉号表示），于是使 CPU 陷入到操作系统，这个陷阱称为缺页中断或缺页错误(page fault)。操作系统找到一个很少使用的页框且把它的内容写入磁盘（如果它不在磁盘上)。 随后把需要访问的页面读到刚才回收的页框中，修改映射关系，然后重新启动引起陷阱的指令。 地址结构构造\n输入的16位虚拟地址：|0|0|1|0|0|0|0|0|0|0|0|0|0|1|0|0| 中间过程通过查找页表：001 变页表中查到的 110；而后面的偏移量不变\n输出的16位虚拟地址：|1|1|0|0|0|0|0|0|0|0|0|0|0|1|0|0| 4 位页号 12 位偏移量 可以表示 16 个页面 可以为一页内的全部 4096 个字节编址 通常，可以用页号作为页表的索引，以得出对应于该虚拟页面的页框号： 在/不在 位是 0，则将引起一个 OS 陷阱 若该位是 1，则将在页表中查到的页框号复制到输出 Reg 的高 3 位中，再加上输入虚拟地址中的 12 位偏移量，如此就构成了 15 位的物理地址。 输出 reg 的内容随即被作为物理地址送到内存总线 页表 为了便于在内存中找到进程的每个页面所对应的物理块，系统为每个进程建立一张页表，记录页面在内存中对应的物理块号，页表一般存放在内存中。\n作为一种最简单的实现，虚拟地址到物理地址的映射可以概括如下：虚拟地址被分成虚拟页号（高位部分)和偏移量（低位部分）两部分。 例如，对于 16 位地址和 4KB 的页面大小，高 4 位可以指定 16 个虚拟页面中的一页，而低 12 位接着确定了所选页面中的字节偏移量(0~4095)。但是使用 3 或者 5 或者其他位数拆分虚拟地址也是可行的。不同的划分对应不同的页面大小。 虚拟页号可用作页表的索引,以找到该虚拟页面对应的页表项。 由页表项可以找到页框号。然后把页框号拼接到偏移量的高位端，以替换掉虚拟页号，形成送往内存的物理地址 页表的目的是把虚拟页面映射为页框\n从数学角度上讲，页表就是一个函数，其参数是虚拟页号，结果是物理页框号。 通过这个函数可以把虚拟地址中的虚拟页面域替换成页框域，从而形成物理地址 在配置了页表后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号。可见，页表的作用是实现从页号到物理块号的地址映射 为了方便 CPU 高效执行管理物理内存，每一次都需要从虚拟内存中拿一个页的代码放到物理内存。虚拟内存页有三种状态，分别是未分配、已缓存和未缓存状态。\n未分配： 指的是未被操作系统分配或者创建的，未分配的虚拟页不存在任何数据和代码与它们关联，因此不占用磁盘资源； 已缓存： 表示的是物理内存中已经为该部分分配的，存在虚拟内存和物理内存映射关系的；——即 DRAM 未缓存： 指的是已经加载到虚拟内存中的，但是未在物理内存中建立映射关系的 利用页表实现对更大虚拟地址空间的映射：\n地址变换机构 MMU 地址变换机构的任务是将逻辑地址转换为内存中物理地址，地址变换是借助于页表实现的。\n在系统中通常设置一个页表寄存器(PTR)，存放页表在内存的始址 F 和页表长度 M。 进程未执行时，页表的始址和长度存放在进程控制块中 当进程执行时，才将页表始址和长度存入页表寄存器。 设页面大小为L，逻辑地址A到物理地址E的变换过程如下： 1. 计算页号P(P=A/L)和页内偏移量W (W=A%L)。 2. 比较页号P和页表长度M，若P \u003e= M，则产生越界中断，否则继续执行。 3. 页表中页号P对应的页表项地址 = 页表起始地址F + 页号P * 页表项长度，取出该页表项内容b，即为物理块号。 4. 计算E=b*L+W，用得到的物理地址E去访问内存。 例如，若页面大小L为1K字节，页号2对应的物理块为b=8，计算逻辑地址A=2500 的物理地址E的过程如下：P=2500/1K=2，W=2500%1K=452，查找得到页号2对应的物理块的块号为 8，E=8*1024+452=8644。 以上整个地址变换过程均是由硬件自动完成的。\n下面讨论分页管理方式存在的两个主要问题： 每次访存操作都需要进行逻辑地址到物理地址的转换，地址转换过程必须足够快，否则访存速度会降低；——TLB 每个进程引入了页表，用于存储映射机制，页表不能太大，否则内存利用率会降低。——多级页表 TLB 在任何分页系统中，都需要考虑两个主要问题：\n虚拟地址到物理地址的映射必须非常快 如果虚拟地址空间很大，页表也会非常大 第一个问题是由于每次访问内存都需要进行虚拟地址到物理地址的映射，所有的指令最终都必须来自内存，并且很多指令也会访问内存中的操作数\n第二个问题来自现代计算机至少使用 32 位的虚拟地址。假设 32 位系统，则其地址空间将有 100 万页。如果虚拟地址空间中有 100 万页，那么页表必然有 100 万条表项。\n并且每个进程都有自己的页表。因为它有自己的虚拟地址空间 对大而快速的页顶映射的需求成为构建计算机的重要约束。最简单的设计（至少从概念上）是使用由“快速硬件寄存器”阵列组成的单一页表，每一个表项对应一个虚拟页面，虚拟页号作为索引\n当启动一个进程时，操作系统把保存在内存中的进程页表的副本载入到寄存器中。在进程运行过程中，不必再为页表而访问内存。 这个方法的优势是简单并且在映射过程中不需要访问内存。 而缺点是在页表很大时，代价高昂。而且每一次上下文切换都必须装载整个页表，这样会降低性能。 大多数的优化技术都是从内存中的页表开始的。这种设计对效率有巨大的影响\n在不分页情况下，这条指令只访存一次：即从内存中取指令 在分页机制下，会因为要访问页表而引起更多次的内存访问。 解决方案则是建立在这样一种观察：大多数程序总是对少量页面进行多次的访问，而不是相反。——即[[#工作集|工作集背后的局部性原理]]\n上面提到的解决方案是为计算机设置一个小型的硬件设备,将虚拟地址直接映射到物理地址,而不必再访问页表。——即 TLB\n转换检测缓冲区 Translation Lookaside Buffer, TLB\n本质就是一张小型的页表 又被称为相联存储器，或快表 它通常在 MMU 中，仅包含少量的表项，很少会超过 256 个——表大小得到控制 每个表项纪录了一个页面的相关信息，包括虚拟页号、页面修改位、保护码以及该页对应的物理页框 TLB 工作原理\n将一个虚拟地址放入 MMU 中进行转换时，硬件首先通过将该虚拟页号与 TLB 中所有表项同时（即并行）进行匹配，判断虚拟页面是否在其中。 如果发现了一个有效的匹配并且要进行的访问操作并不违反保护位， 则将页框号直接从 TLB 中取出而不必再访问页表。 Q：当虚拟页号不在 TLB 中会怎样？ 若 MMU 检测到没有匹配项，就会进行正常的页表检查 接着从 TLB 中淘汰一个表项，然后用新的页表项代替它。 这样,如果这一页面很快被再次访问,第二次访间 TLB 时自然将会命中而不是未命中。 当一个表项被清除出 TLB 时,将修改位复制到内存中的页表项,而除了访问位,其他的值不变。当页表项中从页表中装入 TLB 中时,所有的值都来自内存。 在具有快表的分页机制中，地址的变换过程：\nCPU 给出逻辑地址后，由硬件进行地址转换并将页号送入高速缓存寄存器，并将此页号与快表中的所有页号进行比较。 如果找到匹配的页号，说明所要访问的页表项在快表中，则直接从中取出该页对应的页框号，与页内偏移量拼接形成物理地址。这样，存取数据仅一次访存便可实现。 如果没有找到，则需要访问主存中的页表，在读出页表项后，应同时将其存入快表，以便后面可能的再次访问。但若快表已满，则必须按照一定的算法对旧的页表项进行替换。 注意：有些处理机设计为快表和慢表同时查找，如果在快表中查找成功则终止慢表的查找。\n在这种设计中，对 TLB 的管理和 TLB 的失效处理都完全由 MMU 硬件来实现。只有在内存中没有找到某个页面时，才会陷入到操作系统中。\n而如果当 TLB 大到一定程度可以减少是效率时，TLB 的软件管理就会变的足够有效。这种方法的好处是获得了一个非常简单的 MMU。而这就在片上为高速缓存以及其他性能改善腾出了空间。\n使用软件管理 TLB 时的两种失效 软失效——仅在内存范围内处理 即一个页面访问在内存中而不在 TLB 中。 此时需要做的就是更新 TLB，无需产生磁盘 IO 硬失效——与外围磁盘 IO 有关 此刻需要一次磁盘存取以装入该页面，需要高达 ms 级别的时间 硬失效的处理时间往往是软失效的百万倍 在页表中进行查找相应的映射被称为页表遍历 一般快表的命中率可以达到 90% 以上，这样，分页带来的速度损失就降低到 10% 以下。快表的有效性是基于著名的局部性原理，这在后面的虚拟内存中将会具体讨论。\n多级页表 ——即针对大内存的页表\n引入多级页表的原因是避免把全部页表一直保存在内存中。\n特别是那些从不需要的页表就不应该保留：比如一个需要 12MB 内存的进程，其最底端是 4MB 的程序正文段，后面是 4MB 的数据段，顶端是 4MB 的堆栈段——在数据段上方和数据段下方之间是大量根本没有使用的空闲区 将页表映射的思想进一步延伸，就可以得到二级分页：\n将页表的 10 页空间也进行地址映射，建立上一级页表，用于存储页表的映射关系。这里对页表的 10 个页面进行映射只需要 10 个页表项，所以上一级页表只需要 1 页就足够（可以存储 2^10=1024 个页表项）。 在进程执行时，只需要将这 1 页的上一级页表调入内存即可，进程的页表和进程本身的页面，可以在后面的执行中再调入内存。 举例，32位系统中进程分页的工作过程：假定内核已经给一个正在运行的进程分配的逻辑地址空间是0x20000000到0x2003FFFF，这个空间由64个页面组成。在进程运行时，我们不需要知道全部这些页的页框的物理地址，很可能其中很多页还不在主存中。这里我们只注意在进程运行到某一页时，硬件是如何计算得到这一页的页框的物理地址即可。现在进程需要读逻辑地址0x20021406中的字节内容，这个逻辑地址按如下进行处理： 逻辑地址： 0x20021406 (0010 0000 0000 0010 0001 0100 0000 0110 B) 顶级页表字段：0x80 (00 1000 0000 B) 二级页表字段：0x21 (00 0010 0001B) 页内偏移量字段：0x406 (0100 0000 0110 B) 顶级页表字段的0x80用于选择顶级页表的第0x80表项，此表项指向和该进程的页相关的二级页表；二级页表字段0x21用于选择二级页表的第0x21表项，此表项指向包含所需页的页框；最后的页内偏移量字段0x406用于在目标页框中读取偏移量为0x406中的字节。 这是32位系统下比较实际的一个例子。看似较为复杂的例子，有助于比较深入地理解，希望读者能自己动手计算一遍转换过程。 建立多级页表的目的在于建立索引，这样不用浪费主存空间去存储无用的页表项，也不用盲目地顺序式查找页表项，而建立索引的要求是最高一级页表项不超过一页的大小。在 64 位操作系统中，页表的划分则需要重新考虑，这是很多教材和辅导书中的常见题目，但是很多都给出了错误的分析，需要注意。 我们假设仍然釆用4KB页面大小。偏移量字段12位，假设页表项大小为8B。这样，其上一级分页时，每个页框只能存储29(4KB/8B)个页表项，而不再是210个，所以上一级页表字段为9位。后面同理继续分页。64=12+9+9+9+9+9+7，所以需6级分页才能实现索引。很多书中仍然按4B页表项分析，虽然同样得出6级分页的结果，但显然是错误的。这里给出两个实际的64位操作系统的分页级别（注意：里面没有使用全部64位寻址，不过由于地址字节对齐的设计考虑，仍然使用8B大小的页表项），理解了表3-2中的分级方式，相信对多级分页就非常清楚了。 分段管理 分页管理方式是从计算机的角度考虑设计的，以提高内存的利用率，提升计算机的性能, 且分页通过硬件机制实现，对用户完全透明；\n而分段管理方式的提出则是考虑了用户和程序员，以满足方便编程、信息保护和共享、动态增长及动态链接等多方面的需要。\nQ：为什么需要分段？ 对许多问题来说，有两个或多个独立的地址空间可能比只有一个要好得多。 比如，一个编译器在编译过程中会建立许多表，其中可能包括： 被保存起来的源程序正文 符号表，包含变量的名字和属性 包含用到的所有整型量和浮点常量的表 语法分析树。包含程序语法分析的结果 编译器内部过程调用使用的堆栈。 地址空间不足问题 在这种情况下，如果一个程序中的变量数量要远比其他部分多的时候。地址空间中分配给符号表的块可能会被装满，但这时其他表中还有大量的空间 分段 段式管理方式按照用户进程中的自然段划分逻辑空间。例如，用户进程由主程序、两个子程序、栈和一段数据组成，于是可以把这个用户进程划分为 5 个段，每段从 0 开始编址，并分配一段连续的地址空间（段内要求连续，段间不要求连续，因此整个作业的地址空间是二维的）。其逻辑地址由段号 S 与段内偏移量 W 两部分组成。\n分段 在机器上提供多个互相独立的称为段(segment)的地址空间。 分段是指在用户编程时，将程序按照逻辑划分为几个逻辑段 段 基本性质 每个段由一个从 0 到最大的线性地址序列构成 各个段的长度可以是 0 到最大值间任意值 不同段长度可以不同，并且通常也不会相同 段的长度在运行期间可以动态改变 段是一个逻辑实体 可包括一个过程、一个数组、一个堆栈、一组数值变量。但不会包含不同类型的内容。 段号 段内偏移量 31…16 15…0 段号为 16 位，段内偏移量为 16 位，则一个作业最多可有 2^16=65536 个段，最大段长为 64KB。\n在页式系统中，逻辑地址的页号和页内偏移量对用户是透明的，但在段式系统中，段号和段内偏移量必须由用户显示提供，在髙级程序设计语言中，这个工作由编译程序完成。 段表\n每个进程都有一张逻辑空间与内存空间映射的段表，其中每一个段表项对应进程的一个段，段表项记录该段在内存中的起始地址和段的长度。 段号 段长 本段在主存的起始地址 在配置了段表后，执行中的进程可通过查找段表，找到每个段所对应的内存区。可见，段表用于实现从逻辑段到物理内存区的映射 对于地址空间不足问题的解决-即分段管理优势 1：对地址空间的更灵活利用\n因为每个段都构成了一个独立的地址空间,所以它们可以独立地增长或减小而不会影响到其他的段。 如果一个在某个段中的堆栈需要更多的空间,它就可以立刻得到所需要的空间,因为它的地址空间中没有任何其他东西阻挡它增长。 页式存储管理只有内部碎片；段式存储管理只有外部碎片 分段管理优势 2：对编译链接的过程优化\n把单独编译好的过程链接起来的操作可以得到很大的简化 在一维地址中：过程被像数组中元素一样紧贴排列。因此修改一个过程的大小会影响到其他无关过程的起始地址。开销非常巨大 而在二维地址中：对段 n 过程的调用将使用两部分组成的地址 (n,0) 来寻址到字 0 入口点 分段管理优势 3：便于进程间共享过程和数据\n最常见的例子就是共享库 在分段系统中，可以把图形库放到一个单独的段中供各个进程共享，从而不需要在每个进程的地址空间单独保存一份。 单纯的分页系统中也可以实现共享库的功能，但实际上要复杂很多，并且还是通过模拟分段实现的 段的共享是通过两个作业的段表中相应表项指向被共享的同一个物理副本实现的。，因此在内存中仅仅保存一份段S的内容。此时物理段号相同，但逻辑段号根据每个进程本身决定 地址变换机构 MMU 分段系统的地址变换过程如图 3-15 所示。为了实现进程从逻辑地址到物理地址的变换功能，在系统中设置了段表寄存器，用于存放段表始址 F 和段表长度 M。其从逻辑地址 A 到物理地址 E 之间的地址变换过程如下：\n- 从逻辑地址A中取出前几位为段号S，后几位为段内偏移量W。 - 比较段号S和段表长度M，若S多M，则产生越界中断，否则继续执行。 - 段表中段号S对应的段表项地址 = 段表起始地址F + 段号S * 段表项长度，取出该段表项的前几位得到段长C。若段内偏移量\u003e=C，则产生越界中断，否则继续执行。 - 取出段表项中该段的起始地址b，计算 E = b + W，用得到的物理地址E去访问内存。 段的共享与保护 在分段系统中，段的共享是通过两个作业的段表中相应表项指向被共享的段的同一个物理副本来实现的。\n当一个作业正从共享段中读取数据时，必须防止另一个作业修改此共享段中的数据。不能修改的代码称为纯代码或可重入代码（它不属于临界资源)，这样的代码和不能修改的数据是可以共享的，而可修改的代码和数据则不能共享。\n与分页管理类似，分段管理的保护方法主要有两种：\n一种是存取控制保护，另一种是地址越界保护。地址越界保护是利用段表寄存器中的段表长度与逻辑地址中的段号比较，若段号大于段表长度则产生越界中断；再利用段表项中的段长和逻辑地址中的段内位移进行比较，若段内位移大于段长，也会产生越界中断。 段页式管理 页式存储管理能有效地提高内存利用率，而分段存储管理能反映程序的逻辑结构并有利于段的共享。如果将这两种存储管理方法结合起来，就形成了段页式存储管理方式。\n如果一个段比较大，把它整个保存在内存中可能很不方便甚至是不可能的，因此产生了对它进行分页的想法。这样，只有那些真正需要的页面才会被调入内存。——使用段页式存储管理的原因\n段页式管理的本质：对段进行分页操作\n在段页式系统中，作业的地址空间首先被分成若干个逻辑段，每段都有自己的段号，然后再将每一段分成若干个大小固定的页。对内存空间的管理仍然和分页存储管理一样，将其分成若干个和页面大小相同的存储块，对内存的分配以存储块为单位 在段页式系统中，作业的逻辑地址分为三部分：段号、页号和页内偏移量\n段号 S 页号 P 页内偏移量 W ==为了实现地址变换，系统为每个进程建立一张段表，而每个分段有一张页表。== 段表表项中至少包括段号、页表长度和页表起始地址，页表表项中至少包括页号和块号。此外，系统中还应有一个段表寄存器，指出作业的段表起始地址和段表长度。 注意：在一个进程中，段表只有一个，而页表可能有多个。 在进行地址变换时，首先通过段表查到页表起始地址，然后通过页表找到页帧号，最后形成物理地址。 进行一次访问实际需要三次访问主存，这里同样可以使用快表以加快查找速度，其关键字由段号、页号组成，值是对应的页帧号和保护码。 2 虚拟内存管理 传统存储管理方式的特征 上一节所讨论的各种内存管理策略都是为了同时将多个进程保存在内存中以便允许多道程序设计。它们都具有以下两个共同的特征：\n一次性 作业必须一次性全部装入内存后，方能开始运行。这会导致两种情况发生： 当作业很大，不能全部被装入内存时，将使该作业无法运行； 当大量作业要求运行时，由于内存不足以容纳所有作业，只能使少数作业先运行，导致多道程序度的下降。 驻留性 作业被装入内存后，就一直驻留在内存中，其任何部分都不会被换出，直至作业运行结束。运行中的进程，会因等待 I/O 而被阻塞，可能处于长期等待状态。 由以上分析可知，许多在程序运行中不用或暂时不用的程序（数据）占据了大量的内存空间，而一些需要运行的作业又无法装入运行，显然浪费了宝贵的内存资源。 局部性原理 要真正理解虚拟内存技术的思想，首先必须了解计算机中著名的局部性原理。\n著名的 Bill Joy (SUN 公司 CEO)说过：”在研究所的时候，我经常开玩笑地说高速缓存是计算机科学中唯一重要的思想。事实上，髙速缓存技术确实极大地影响了计算机系统的设计。“快表、 页高速缓存以及虚拟内存技术从广义上讲，都是属于高速缓存技术。这个技术所依赖的原理就是局部性原理。局部性原理既适用于程序结构，也适用于数据结构（更远地讲，Dijkstra 著名的关于“goto 语句有害”的论文也是出于对程序局部性原理的深刻认识和理解）。\n局部性原理表现在以下两个方面： 时间局部性： 如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。 空间局部性： 一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。 时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。\n虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。\n虚存的定义和特征 基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其余部分留在外存，就可以启动程序执行。 在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存,然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换出到外存上，从而腾出空间存放将要调入内存的信息。这样，系统好像为用户提供了一个比实际内存大得多的存储器，称为虚拟存储器。 之所以将其称为虚拟存储器，是因为这种存储器实际上并不存在，只是由于系统提供了部分装入、请求调入和置换功能后（对用户完全透明），给用户的感觉是好像存在一个比实际物理内存大得多的存储器。\n虚拟存储器的大小由计算机的地址结构决定，并非是内存和外存的简单相加。虚拟存储器有以下三个主要特征： 多次性 是指无需在作业运行时一次性地全部装入内存，而是允许被分成多次调入内存运行。 对换性 是指无需在作业运行时一直常驻内存，而是允许在作业的运行过程中，进行换进和换出。 虚拟性 是指从逻辑上扩充内存的容量，使用户所看到的内存容量，远大于实际的内存容量。 虚存技术的实现 虚拟内存中，允许将一个作业分多次调入内存。釆用连续分配方式时，会使相当一部分内存空间都处于暂时或“永久”的空闲状态，造成内存资源的严重浪费，而且也无法从逻辑上扩大内存容量。因此，虚拟内存的实需要建立在离散分配的内存管理方式的基础上。\n虚拟内存的实现有以下三种方式：\n请求分页存储管理。 请求分段存储管理。 请求段页式存储管理。 不管哪种方式，都需要有一定的硬件支持。一般需要的支持有以下几个方面：\n一定容量的内存和外存。 页表机制（或段表机制），作为主要的数据结构。 中断机构，当用户程序要访问的部分尚未调入内存，则产生中断。 地址变换机构，逻辑地址到物理地址的变换。 请求页式管理实现虚存 请求分页系统建立在基本分页系统基础之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。\n请求分页是目前最常用的一种实现虚拟存储器的方法。\n在请求分页系统中，只要求将当前需要的一部分页面装入内存，便可以启动作业运行。在作业执行过程中，当所要访问的页面不在内存时，再通过调页功能将其调入，同时还可以通过置换功能将暂时不用的页面换出到外存上，以便腾出内存空间。 为了实现请求分页，系统必须提供一定的硬件支持。除了需要一定容量的内存及外存的计算机系统，还需要有页表机制、缺页中断机构和地址变换机构。 页表机制 请求分页系统的页表机制不同于基本分页系统，请求分页系统在一个作业运行之前不要求全部一次性调入内存，因此在作业的运行过程中，必然会出现要访问的页面不在内存的情况，如何发现和处理这种情况是请求分页系统必须解决的两个基本问题。为此，在请求页表项中增加了四个字段\n页号 物理块号 状态位 P 访问字段 A 修改位 M 外存地址 增加的四个字段说明如下：\n状态位 P：用于指示该页是否已调入内存，供程序访问时参考。 访问字段 A：用于记录本页在一段时间内被访问的次数，或记录本页最近己有多长时间未被访问，供置换算法换出页面时参考。 修改位 M：标识该页在调入内存后是否被修改过。 外存地址：用于指出该页在外存上的地址，通常是物理块号，供调入该页时参考。 缺页中断机构 在请求分页系统中，每当所要访问的页面不在内存时，便产生一个缺页中断，请求操作系统将所缺的页调入内存。此时应将缺页的进程阻塞（调页完成唤醒)，如果内存中有空闲块，则分配一个块，将要调入的页装入该块，并修改页表中相应页表项，若此时内存中没有空闲块，则要淘汰某页（若被淘汰页在内存期间被修改过，则要将其写回外存)。\n缺页中断作为中断同样要经历，诸如保护 CPU 环境、分析中断原因、转入缺页中断处理程序、恢复 CPU 环境等几个步骤。但与一般的中断相比，它有以下两个明显的区别：\n在指令执行期间产生和处理中断信号，而非一条指令执行完后，属于内部中断。 一条指令在执行期间，可能产生多次缺页中断。 地址变换机构 请求分页系统中的地址变换机构，是在分页系统地址变换机构的基础上，为实现虚拟内存，又增加了某些功能而形成的。\n在进行地址变换时，先检索 TLB： 若找到要访问的页，便修改页表项中的访问位（写指令则还须重置修改位)，然后利用页表项中给出的物理块号和页内地址形成物理地址。 若未找到该页的页表项，应到内存中去查找页表，再对比页表项中的状态位 P，看该页是否已调入内存，未调入则产生缺页中断，请求从外存把该页调入内存。 页面置换算法 进程运行时，若其访问的页面不在内存而需将其调入，但内存已无空闲空间时，就需要从内存中调出一页程序或数据，送入磁盘的对换区。\n选择调出页面的算法就称为页面置换算法。好的页面置换算法应有较低的页面更换频率，也就是说，应将以后不会再访问或者以后较长时间内不会再访问的页面先调出。\n最佳置换算法 OPT 最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。\n但由于人们目前无法预知进程在内存下的若干页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。\n最佳置换算法可以用来评价其他算法。 假定系统为某进程分配了三个物理块，并考虑有以下页面号引用串： 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1 进程运行时，先将7, 0, 1三个页面依次装入内存。进程要访问页面2时，产生缺页中断，根据最佳置换算法，选择第18次访问才需调入的页面7予以淘汰。然后，访问页面0时，因为已在内存中所以不必产生缺页中断。访问页面3时又会根据最佳置换算法将页面1淘汰……依此类推，如图3-26所示。从图中可以看出釆用最佳置换算法时的情况。 可以看到，发生缺页中断的次数为9，页面置换的次数为6。 先进先出 FIFO 优先淘汰最早进入内存的页面，亦即在内存中驻留时间最久的页面。\n该算法实现简单，只需把调入内存的页面根据先后次序链接成队列，设置一个指针总指向最早的页面。 但该算法与进程实际运行时的规律不适应，因为在进程中，有的页面经常被访问。 这里仍用上面的实例，釆用FIFO算法进行页面置换。进程访问页面2时，把最早进入内存的页面7换出。然后访问页面3时，再把2, 0, 1中最先进入内存的页换出。由图 3-27可以看出，利用FIFO算法时进行了 12次页面置换，比最佳置换算法正好多一倍。 Belady 异常\nFIFO 算法还会产生当所分配的物理块数增大而页故障数不减反增的异常现象，这是由 Belady 于 1969 年发现，故称为 Belady 异常 只有 FIFO 算法可能出现 Belady 异常，而 LRU 和 OPT 算法永远不会出现 Belady 异常。 最近最久未使用 LRU 选择最近最长时间未访问过的页面予以淘汰，它认为过去一段时间内未访问过的页面，在最近的将来可能也不会被访问。\n该算法为每个页面设置一个访问字段，来记录页面自上次被访问以来所经历的时间，淘汰页面时选择现有页面中值最大的予以淘汰。 再对上面的实例釆用LRU算法进行页面置换，如图3-29所示。进程第一次对页面2访问时，将最近最久未被访问的页面7置换出去。然后访问页面3时，将最近最久未使用的页面1换出。 在图 3-29 中，前 5 次置换的情况与最佳置换算法相同，但两种算法并无必然联系。\n实际上，LRU 算法根据各页以前的情况，是“向前看”的 而最佳置换算法则根据各页以后的使用情况，是“向后看”的，所以 OPT 算法无法真正实现。 LRU 性能较好，但需要寄存器和栈的硬件支持。\nLRU 是堆栈类的算法。理论上可以证明，堆栈类算法不可能出现 Belady 异常。FIFO 算法基于队列实现，不是堆栈类算法。\n时钟置换算法 CLOCK LRU 算法的性能接近于 OPT,但是实现起来比较困难，且开销大；FIFO 算法实现简单，但性能差。所以操作系统的设计者尝试了很多算法，试图用比较小的开销接近 LRU 的性能，这类算法都是 CLOCK 算法的变体。\n一个更好的办法是把所有的页面都保存在一个类似钟面的环形链表中,一个表针指向最老的页面\n当发生缺页中断时，算法首先检查表指针指向的页面 如果它的 R 位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置 如果它的 R 位是 1 就清除 R 位，设置为 0，并把表针前移一个位置。 重复这个过程直到找到一个 R 位 0 的页面为止。 简单的 CLOCK 算法是给每一帧关联一个附加位，称为使用位。当某一页首次装入主存时，该帧的使用位设置为 1;当该页随后再被访问到时，它的使用位也被置为 1。对于页替换算法，用于替换的候选帧集合看做一个循环缓冲区，并且有一个指针与之相关联。当某一页被替换时，该指针被设置成指向缓冲区中的下一帧。 当需要替换一页时，操作系统扫描缓冲区，以查找使用位被置为 0 的一帧。每当遇到一个使用位为 1 的帧时，操作系统就将该位重新置为 0；如果在这个过程开始时，缓冲区中所有帧的使用位均为 0，则选择遇到的第一个帧替换；如果所有帧的使用位均为 1,则指针在缓冲区中完整地循环一周，把所有使用位都置为 0，并且停留在最初的位置上，替换该帧中的页。 由于该算法循环地检查各页面的情况，故称为 CLOCK 算法，又称为最近未用(Not Recently Used, NRU)算法。 LRU 的各种变体算法——改进型CLOCK置换算法\nCLOCK 算法的性能比较接近 LRU，而通过增加使用的位数目，可以使得 CLOCK 算法更加高效。在使用位的基础上再增加一个修改位，则得到改进型的 CLOCK 置换算法。这样，每一帧都处于以下四种情况之一：\n最近未被访问，也未被修改(u=0, m=0)。 最近被访问，但未被修改(u=1, m=0)。 最近未被访问，但被修改(u=0, m=1)。 最近被访问，被修改(u=1, m=1)。 算法执行如下操作步骤：\n从指针的当前位置开始，扫描帧缓冲区。在这次扫描过程中，对使用位不做任何修改。选择遇到的第一个帧(u=0, m=0)用于替换。 如果第 1 步失败，则重新扫描，查找(u=0, m=1)的帧。选择遇到的第一个这样的帧用于替换。在这个扫描过程中，对每个跳过的帧，把它的使用位设置成 0。 如果第 2 步失败，指针将回到它的最初位置，并且集合中所有帧的使用位均为 0。重复第 1 步，并且如果有必要，重复第 2 步。这样将可以找到供替换的帧。 改进型的 CLOCK 算法优于简单 CLOCK 算法之处在于替换时首选没有变化的页。由于修改过的页在被替换之前必须写回，因而这样做会节省时间。\n页面分配策略 驻留集 对于分页式的虚拟内存，在准备执行时，不需要也不可能把一个进程的所有页都读取到主存，因此，操作系统必须决定读取多少页。也就是说，给特定的进程分配多大的主存空间，这需要考虑以下几点：\n分配给一个进程的存储量越小，在任何时候驻留在主存中的进程数就越多，从而可以提高处理机的时间利用效率。 如果一个进程在主存中的页数过少，尽管有局部性原理，页错误率仍然会相对较高。 如果页数过多，由于局部性原理，给特定的进程分配更多的主存空间对该进程的错误率没有明显的影响。 三种驻留集大小分配策略\n固定分配局部置换。 它为每个进程分配一定数目的物理块，在整个运行期间都不改变。若进程在运行中发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后再调入需要的页面。 实现这种策略难以确定为每个进程应分配的物理块数目：太少会频繁出现缺页中断，太多又会使 CPU 和其他资源利用率下降。 可变分配全局置换。 这是最易于实现的物理块分配和置换策略，为系统中的每个进程分配一定数目的物理块,操作系统自身也保持一个空闲物理块队列。 当某进程发生缺页时，系统从空闲物理块队列中取出一个物理块分配给该进程，并将欲调入的页装入其中 可变分配局部置换。 它为每个进程分配一定数目的物理块，当某进程发生缺页时，只允许从该进程在内存的页面中选出一页换出，这样就不会影响其他进程的运行。 如果进程在运行中频繁地缺页，系统再为该进程分配若干物理块，直至该进程缺页率趋于适当程度； 反之，若进程在运行中缺页率特别低，则可适当减少分配给该进程的物理块。 页面调入时机 为确定系统将进程运行时所缺的页面调入内存的时机，可釆取以下两种调页策略：\n预调页策略。\n根据局部性原理，一次调入若干个相邻的页可能会比一次调入一页更高效。但如果调入的一批页面中大多数都未被访问，则又是低效的。 所以就需要釆用以预测为基础的预调页策略，将预计在不久之后便会被访问的页面预先调入内存。但目前预调页的成功率仅约 50%。故这种策略主要用于进程的首次调入时，由程序员指出应该先调入哪些页。 请求调页策略。\n进程在运行中需要访问的页面不在内存而提出请求，由系统将所需页面调入内存。 由这种策略调入的页一定会被访问，且这种策略比较易于实现，故在目前的虚拟存储器中大多釆用此策略。它的缺点在于每次只调入一页，调入调出页面数多时会花费过多的 I/O 开销。 Q：从何处调入页面？\n请求分页系统中的外存分为两部分：用于存放文件的文件区和用于存放对换页面的对换区。 对换区通常是釆用连续分配方式，而文件区釆用离散分配方式，故对换区的磁盘 I/O 速度比文件区的更快。这样从何处调入页面有三种情况： 系统拥有足够的对换区空间：可以全部从对换区调入所需页面，以提髙调页速度。为此，在进程运行前，需将与该进程有关的文件从文件区复制到对换区。 系统缺少足够的对换区空间：凡不会被修改的文件都直接从文件区调入；而当换出这些页面时，由于它们未被修改而不必再将它们换出。但对于那些可能被修改的部分，在将它们换出时须调到对换区，以后需要时再从对换区调入。 UNIX 方式：与进程有关的文件都放在文件区，故未运行过的页面，都应从文件区调入。曾经运行过但又被换出的页面，由于是被放在对换区，因此下次调入时应从对换区调入。进程请求的共享页面若被其他进程调入内存，则无需再从对换区调入。 抖动 在页面置换过程中的一种最糟糕的情形是，刚刚换出的页面马上又要换入主存，刚刚换入的页面马上就要换出主存，这种频繁的页面调度行为称为抖动，或颠簸。\n如果一个进程在换页上用的时间多于执行时间，那么这个进程就在颠簸。 频繁的发生缺页中断（抖动），其主要原因是某个进程频繁访问的页面数目高于可用的物理页帧数目。 虚拟内存技术可以在内存中保留更多的进程以提髙系统效率。在稳定状态，几乎主存的所有空间都被进程块占据，处理机和操作系统可以直接访问到尽可能多的进程。 但如果管理不当，处理机的大部分时间都将用于交换块，即请求调入页面的操作，而不是执行进程的指令，这就会大大降低系统效率。 工作集 工作集（或驻留集）是指在某段时间间隔内，进程要访问的页面集合。\n经常被使用的页面需要在工作集中，而长期不被使用的页面要从工作集中被丢弃。为了防止系统出现抖动现象，需要选择合适的工作集大小。 工作集模型的原理是：让操作系统跟踪每个进程的工作集，并为进程分配大于其工作集的物理块。 如果还有空闲物理块，则可以再调一个进程到内存以增加多道程序数。 如果所有工作集之和增加以至于超过了可用物理块的总数，那么操作系统会暂停一个进程，将其页面调出并且将其物理块分配给其他进程，防止出现抖动现象。 正确选择工作集的大小，对存储器的利用率和系统吞吐量的提高，都将产生重要影响。\n小结 分页与分段的区别\n内部碎片与外部碎片🧩\n重点在于理解浪费内存的区域叫做碎片，而内部和外部是相对于当前使用的分配结构来说的 内部碎片：在一个分配结构块内产生的碎片。无法被其他进程或作业再次利用 如固定分区，每块区域大小固定的。 如分页管理，每一页尽管大小很小，并且在有些 OS 中提供了不同的种类选择，但依旧是基本相同的固定大小。 如段页式，其本质还是将分段后的内存页面化存储。则与分页管理的存储本质完全相同 外部碎片：在分配结构之间的碎片。可以随着使用和优化被其他进程或碎片再次利用 如动态分区管理，其所采用的最先适应，最佳适应，最坏适应，临近适应，就是为了更好地利用外部碎片而生的 如段式管理，每个段是动态不固定的，由当前的进程需求决定分配的大小。故和动态分区非常类似，会产生段间内存碎片，即外部碎片。 THINK：后续的这些实现虚存的算法，是否是之前简单算法思想的延续？ ","wordCount":"1153","inLanguage":"en","datePublished":"2022-05-04T11:40:58+08:00","dateModified":"2022-05-04T11:40:58+08:00","author":{"@type":"Person","name":"CaesarYang"},"mainEntityOfPage":{"@type":"WebPage","@id":"/post/tech/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/o3-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"},"publisher":{"@type":"Organization","name":"Caesar's Paperbox","logo":{"@type":"ImageObject","url":"%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href accesskey=h title="Caesar's Paperbox (Alt + H)"><img src=/avatar.jpeg alt aria-label=logo height=35>Caesar's Paperbox</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=archives title=Archives><span>Archives</span></a></li><li><a href=post/life title=Life><span>Life</span></a></li><li><a href=post/reading title=Reading><span>Reading</span></a></li><li><a href=post/tech title=Tech><span>Tech</span></a></li><li><a href=http://storage.cyang.site/resume/%E6%9D%A8%E4%B8%9A%E5%8D%BF%E7%AE%80%E5%8E%86_resume_202210.pdf title="Resume 简历"><span>Resume 简历</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href>Home</a>&nbsp;»&nbsp;<a href=/post/>Articles</a>&nbsp;»&nbsp;<a href=/post/tech/>Tech</a></div><h1 class=post-title>O3-内存管理</h1><div class=post-meta><span title='2022-05-04 11:40:58 +0800 CST'>May 4, 2022</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1153 words&nbsp;·&nbsp;CaesarYang&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/post/tech/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f%e7%ac%94%e8%ae%b0/O3%20%e5%86%85%e5%ad%98%e7%ae%a1%e7%90%86.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#intro aria-label=Intro>Intro</a></li><li><a href=#1-%e5%86%85%e5%ad%98%e7%ae%a1%e7%90%86%e6%a6%82%e5%bf%b5 aria-label="1 内存管理概念">1 内存管理概念</a><ul><li><a href=#%e7%a8%8b%e5%ba%8f%e8%a3%85%e5%85%a5%e4%b8%8e%e9%93%be%e6%8e%a5 aria-label=程序装入与链接>程序装入与链接</a></li><li><a href=#%e9%80%bb%e8%be%91%e5%9c%b0%e5%9d%80%e7%a9%ba%e9%97%b4%e4%b8%8e%e7%89%a9%e7%90%86%e5%9c%b0%e5%9d%80%e7%a9%ba%e9%97%b4 aria-label=逻辑地址空间与物理地址空间>逻辑地址空间与物理地址空间</a></li><li><a href=#%e5%86%85%e5%ad%98%e4%bf%9d%e6%8a%a4 aria-label=内存保护>内存保护</a></li></ul></li><li><a href=#%e8%a6%86%e7%9b%96%e4%b8%8e%e4%ba%a4%e6%8d%a2 aria-label=覆盖与交换>覆盖与交换</a><ul><li><a href=#%e8%a6%86%e7%9b%96 aria-label=覆盖>覆盖</a></li><li><a href=#%e4%ba%a4%e6%8d%a2 aria-label=交换>交换</a></li></ul></li><li><a href=#%e5%86%85%e5%ad%98%e8%bf%9e%e7%bb%ad%e5%88%86%e9%85%8d%e7%ae%a1%e7%90%86 aria-label=内存连续分配管理>内存连续分配管理</a><ul><li><a href=#%e5%8d%95%e4%b8%80%e8%bf%9e%e7%bb%ad%e5%88%86%e9%85%8d aria-label=单一连续分配>单一连续分配</a></li><li><a href=#%e5%9b%ba%e5%ae%9a%e5%88%86%e5%8c%ba%e5%88%86%e9%85%8d aria-label=固定分区分配>固定分区分配</a></li><li><a href=#%e5%8a%a8%e6%80%81%e5%88%86%e5%8c%ba%e5%88%86%e9%85%8d aria-label=动态分区分配>动态分区分配</a></li></ul></li><li><a href=#%e5%86%85%e5%ad%98%e7%9a%84%e9%9d%9e%e8%bf%9e%e7%bb%ad%e5%88%86%e9%85%8d%e7%ae%a1%e7%90%86 aria-label=内存的非连续分配管理>内存的非连续分配管理</a><ul><li><a href=#%e5%88%86%e9%a1%b5%e7%ae%a1%e7%90%86 aria-label=分页管理>分页管理</a><ul><li><a href=#%e5%88%86%e9%a1%b5 aria-label=分页>分页</a></li><li><a href=#%e9%a1%b5%e8%a1%a8 aria-label=页表>页表</a></li><li><a href=#%e5%9c%b0%e5%9d%80%e5%8f%98%e6%8d%a2%e6%9c%ba%e6%9e%84-mmu aria-label="地址变换机构 MMU">地址变换机构 MMU</a></li><li><a href=#tlb aria-label=TLB>TLB</a></li><li><a href=#%e5%a4%9a%e7%ba%a7%e9%a1%b5%e8%a1%a8 aria-label=多级页表>多级页表</a></li></ul></li><li><a href=#%e5%88%86%e6%ae%b5%e7%ae%a1%e7%90%86 aria-label=分段管理>分段管理</a><ul><li><a href=#%e5%88%86%e6%ae%b5 aria-label=分段>分段</a></li><li><a href=#%e5%9c%b0%e5%9d%80%e5%8f%98%e6%8d%a2%e6%9c%ba%e6%9e%84-mmu-1 aria-label="地址变换机构 MMU">地址变换机构 MMU</a></li><li><a href=#%e6%ae%b5%e7%9a%84%e5%85%b1%e4%ba%ab%e4%b8%8e%e4%bf%9d%e6%8a%a4 aria-label=段的共享与保护>段的共享与保护</a></li></ul></li><li><a href=#%e6%ae%b5%e9%a1%b5%e5%bc%8f%e7%ae%a1%e7%90%86 aria-label=段页式管理>段页式管理</a></li></ul></li><li><a href=#2-%e8%99%9a%e6%8b%9f%e5%86%85%e5%ad%98%e7%ae%a1%e7%90%86 aria-label="2 虚拟内存管理">2 虚拟内存管理</a><ul><li><a href=#%e5%b1%80%e9%83%a8%e6%80%a7%e5%8e%9f%e7%90%86 aria-label=局部性原理>局部性原理</a></li><li><a href=#%e8%99%9a%e5%ad%98%e7%9a%84%e5%ae%9a%e4%b9%89%e5%92%8c%e7%89%b9%e5%be%81 aria-label=虚存的定义和特征>虚存的定义和特征</a></li><li><a href=#%e8%99%9a%e5%ad%98%e6%8a%80%e6%9c%af%e7%9a%84%e5%ae%9e%e7%8e%b0 aria-label=虚存技术的实现>虚存技术的实现</a></li></ul></li><li><a href=#%e8%af%b7%e6%b1%82%e9%a1%b5%e5%bc%8f%e7%ae%a1%e7%90%86%e5%ae%9e%e7%8e%b0%e8%99%9a%e5%ad%98 aria-label=请求页式管理实现虚存>请求页式管理实现虚存</a><ul><li><a href=#%e9%a1%b5%e8%a1%a8%e6%9c%ba%e5%88%b6 aria-label=页表机制>页表机制</a></li><li><a href=#%e7%bc%ba%e9%a1%b5%e4%b8%ad%e6%96%ad%e6%9c%ba%e6%9e%84 aria-label=缺页中断机构>缺页中断机构</a></li><li><a href=#%e5%9c%b0%e5%9d%80%e5%8f%98%e6%8d%a2%e6%9c%ba%e6%9e%84 aria-label=地址变换机构>地址变换机构</a></li></ul></li><li><a href=#%e9%a1%b5%e9%9d%a2%e7%bd%ae%e6%8d%a2%e7%ae%97%e6%b3%95 aria-label=页面置换算法>页面置换算法</a><ul><li><a href=#%e6%9c%80%e4%bd%b3%e7%bd%ae%e6%8d%a2%e7%ae%97%e6%b3%95-opt aria-label="最佳置换算法 OPT">最佳置换算法 OPT</a></li><li><a href=#%e5%85%88%e8%bf%9b%e5%85%88%e5%87%ba-fifo aria-label="先进先出 FIFO">先进先出 FIFO</a></li><li><a href=#%e6%9c%80%e8%bf%91%e6%9c%80%e4%b9%85%e6%9c%aa%e4%bd%bf%e7%94%a8-lru aria-label="最近最久未使用 LRU">最近最久未使用 LRU</a></li><li><a href=#%e6%97%b6%e9%92%9f%e7%bd%ae%e6%8d%a2%e7%ae%97%e6%b3%95-clock aria-label="时钟置换算法 CLOCK">时钟置换算法 CLOCK</a></li></ul></li><li><a href=#%e9%a1%b5%e9%9d%a2%e5%88%86%e9%85%8d%e7%ad%96%e7%95%a5 aria-label=页面分配策略>页面分配策略</a><ul><li><a href=#%e9%a9%bb%e7%95%99%e9%9b%86 aria-label=驻留集>驻留集</a></li><li><a href=#%e9%a1%b5%e9%9d%a2%e8%b0%83%e5%85%a5%e6%97%b6%e6%9c%ba aria-label=页面调入时机>页面调入时机</a></li></ul></li><li><a href=#%e6%8a%96%e5%8a%a8 aria-label=抖动>抖动</a></li><li><a href=#%e5%b7%a5%e4%bd%9c%e9%9b%86 aria-label=工作集>工作集</a></li><li><a href=#%e5%b0%8f%e7%bb%93 aria-label=小结>小结</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=intro>Intro<a hidden class=anchor aria-hidden=true href=#intro>#</a></h1><p>内存管理包括内存管理概念、交换与覆盖、连续分配管理方式和非连续分配管理方式（分页管理方式、分段管理方式、段页式管理方式）。</p><p>虚拟内存管理包括虚拟内存概念、请求分页管理方式、页面置换算法、页面分配策略、工作集和抖动。</p><ul><li>3.内存管理<ul><li>（1）内存管理基础<ul><li>1）内存管理概念 ：程序装入与链接，逻辑地址与物理地址空间，内存保护</li><li>2）交换与覆盖</li><li>3）连续分配管理方式</li><li>4）非连续分配管理方式 ：分页管理方式，分段管理方式，段页式管理方式</li></ul></li><li>（2）虚拟内存管理<ul><li>1）虚拟内存基本概念</li><li>2）请求分页管理方式</li><li>3）页面置换算法 ：最佳置换算法（OPT），先进先出置换算法（FIFO），最近最少使用置换算法（LRU），时钟置换算法（CLOCK）</li><li>4）页面分配策略</li><li>5）工作集</li><li>6）抖动</li></ul></li></ul></li></ul><h1 id=1-内存管理概念>1 内存管理概念<a hidden class=anchor aria-hidden=true href=#1-内存管理概念>#</a></h1><p><strong>内存管理(Memory Management)是操作系统设计中最重要和最复杂的内容之一</strong>。</p><blockquote><p>虽然计算机硬件一直在飞速发展，内存容量也在不断增长，但是仍然不可能将所有用户进程和系统所需要的全部程序和数据放入主存中，所以操作系统必须将内存空间进行合理地划分和有效地动态分配。操作系统对内存的划分和动态分配，就是内存管理的概念。</p></blockquote><p><em>有效的内存管理在多道程序设计中非常重要，不仅方便用户使用存储器、提高内存利用率，还可以通过虚拟技术从逻辑上扩充存储器。</em></p><ul><li><strong>内存管理的功能：</strong><ul><li><strong>内存空间的分配与回收</strong>：由操作系统完成主存储器空间的分配和管理，使程序员摆脱存储分配的麻烦，提高编程效率。</li><li><strong>地址转换</strong>：在多道程序环境下，程序中的逻辑地址与内存中的物理地址不可能一致，因此存储管理必须提供地址变换功能，把逻辑地址转换成相应的物理地址。</li><li><strong>内存空间的扩充</strong>：利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存。</li><li><strong>存储保护</strong>：保证各道作业在各自的存储空间内运行，互不干扰。</li></ul></li></ul><h2 id=程序装入与链接>程序装入与链接<a hidden class=anchor aria-hidden=true href=#程序装入与链接>#</a></h2><p><em><strong>创建进程首先要将程序和数据装入内存。</strong></em></p><ul><li><strong>将用户源程序变为可在内存中执行的程序，通常需要以下几个步骤：</strong><ul><li><strong>编译</strong>：由编译程序将用户源代码编译成若干个目标模块。</li><li><strong>链接</strong>：由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块。</li><li><strong>装入</strong>：由装入程序将装入模块装入内存运行。</li></ul></li></ul><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/Screen%20Shot%202022-07-24%20at%2011.47.47.png alt></p><p><strong>程序链接方式：</strong></p><ul><li>静态链接：<ul><li>在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，以后不再拆开。</li></ul></li><li>装入时动态链接：<ul><li>将用户源程序编译后所得到的一组目标模块，在装入内存时，釆用边装入边链接的链接方式。</li></ul></li><li>运行时动态链接：<ul><li>对某些目标模块的链接，是在程序执行中需要该目标模块时，才对它进行的链接。其优点是便于修改和更新，便于实现对目标模块的共享。</li></ul></li></ul><p><strong>内存的装入模块在装入内存时，同样有以下三种方式：</strong></p><ul><li><strong>绝对装入</strong><ul><li>在编译时，如果知道程序将驻留在内存的某个位置，编译程序将产生绝对地址的目标代码。绝对装入程序按照装入模块中的地址，将程序和数据装入内存。<em>由于程序中的逻辑地址与实际内存地址完全相同，故不需对程序和数据的地址进行修改。</em></li><li><strong>绝对装入方式只适用于单道程序环境</strong>。另外，程序中所使用的绝对地址,可在编译或汇编时给出，也可由程序员直接赋予。而通常情况下在程序中釆用的是符号地址，编译或汇编时再转换为绝对地址。</li></ul></li><li><strong>可重定位装入——静态重定位</strong><ul><li><em><strong>在作业运行前一次性装入分配全部所需的内存空间</strong></em></li><li>在多道程序环境下，多个目标模块的起始地址通常都是从 0 开始，程序中的其他地址都是相对于起始地址的,此时应釆用可重定位装入方式。根据内存的当前情况，将装入模块装入到内存的适当位置。</li><li>装入时对目标程序中指令和数据的修改过程称为重定位，地址变换通常是在装入时一次完成的，所以又称为静态重定位。</li><li><em>静态重定位的特点是在一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入该作业</em>。此外，作业一旦进入内存后，在整个运行期间不能在内存中移动，也不能再申请内存空间。</li></ul></li><li><strong>动态运行时装入——动态重定位</strong><ul><li><em><strong>动态运行时，实时将所需内存空间分配并装入，且均为相对地址</strong></em></li><li>程序在内存中如果发生移动，就需要釆用动态的装入方式。装入程序在把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正要执行时才进行。因此，装入内存后的所有地址均为相对地址。</li><li>这种方式需要一个重定位寄存器的支持</li><li><em>动态重定位的特点是可以将程序分配到不连续的存储区中</em>；在程序运行之前可以只装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。</li></ul></li></ul><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/Screen%20Shot%202022-07-24%20at%2011.49.56.png alt></p><ul><li><p><strong>基址寄存器与界限寄存器</strong></p><ul><li>意义：——<em><strong>真正实现了内存地址动态重定位</strong></em></li><li>这个方法利用的就是<strong>动态重定位技术</strong>。即简单地把每个进程的地址空间映射到物理内存的不同部分。</li><li><strong>基址寄存器-即基地址 Reg</strong><ul><li>存储当前的基地址</li></ul></li><li><strong>界限寄存器</strong><ul><li>主要提供地址越界检查保护</li></ul></li><li>此时，程序装载到内存中的连续空闲位置且装载期间无需重定位。<ul><li>程序的起始物理地址装载到基址寄存器</li><li>程序的长度装载到界限寄存器</li></ul></li><li><em>每次一个进程访问内存，取一条指令，读或写一个数据字，CPU 硬件会在把地址发送到内存总线前， 自动把基址值加到进程发出的地址值上。同时，它检查程序提供的地址是否等于或大于界限寄存器里的值。</em></li><li><em>如果访问的地址超过了界限，会产生错误并中止访问。</em></li></ul></li><li><p><em>Q：如何实现动态地址重定位？</em></p><ul><li>因为每个内存地址在送到内存之前,都会自动先加上基址寄存器的内容。</li><li>且在很多实际系统中,对基址寄存器和界限寄存器会以一定的方式加以保护,使得只有操作系统可以修改它们。</li></ul></li><li><p><strong>动态地址重定位</strong></p><ul><li>在程序执行过程中，CPU 访存前，将要访问的程序或数据地址转换为内存地址。动态地址重定位依靠硬件地址变换机构完成。</li><li>具体实现：地址重定位机构</li><li>m 个基地址寄存器 BR+n 个程序虚拟地址寄存器 VR=>共同构成指令或数据的内存地址 MA</li><li>优点：<ul><li>对内存进行连续分配</li><li>是实现虚存的基础</li><li>利于程序段共享</li></ul></li></ul></li></ul><p>$$MA = (BR) + (VR)$$</p><h2 id=逻辑地址空间与物理地址空间>逻辑地址空间与物理地址空间<a hidden class=anchor aria-hidden=true href=#逻辑地址空间与物理地址空间>#</a></h2><ul><li><p><strong>逻辑地址</strong></p><ul><li>编译后，每个目标模块都是从 0 号单元开始编址，称为该目标模块的相对地址（或逻辑地址)。</li><li>当链接程序将各个模块链接成一个完整的可执行目标程序时，链接程序顺序依次按各个模块的相对地址构成统一的从 0 号单元开始编址的逻辑地址空间。用户程序和程序员只需知道逻辑地址，而内存管理的具体机制则是完全透明的，它们只有系统编程人员才会涉及。不同进程可以有相同的逻辑地址，因为这些相同的逻辑地址可以映射到主存的不同位置。</li></ul></li><li><p><strong>物理地址</strong></p><ul><li><strong>物理地址空间是指内存中物理单元的集合，它是地址转换的最终地址</strong>，进程在运行时执行指令和访问数据最后都要通过物理地址从主存中存取。</li><li>当装入程序将可执行代码装入内存时，必须通过地址转换将逻辑地址转换成物理地址，这个过程称为<strong>地址重定位</strong>。</li></ul></li><li><p><strong>基址+界限寄存器的缺点：</strong></p><ul><li>每次访存都需要进行加法和比较运算</li><li>比较运算可以很快；但加法运算由于进位传递时间的问题，在没有特殊电路的情况下会比较慢。</li></ul></li></ul><h2 id=内存保护>内存保护<a hidden class=anchor aria-hidden=true href=#内存保护>#</a></h2><p>内存分配前，需要保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。</p><ul><li>通过釆用重定位寄存器（基址寄存器）和界地址寄存器（界限寄存器）来实现这种保护。</li><li>重定位寄存器含最小的物理地址值，界地址寄存器含逻辑地址值。<ul><li>每个逻辑地址值必须小于界地址寄存器；</li><li>内存管理机构动态地将逻辑地址与界地址寄存器进行比较，如果未发生地址越界，则加上重定位寄存器的值后映射成物理地址，再送交内存单元。</li></ul></li><li>当 CPU 调度程序选择进程执行时，派遣程序会初始化重定位寄存器和界地址寄存器。每一个逻辑地址都需要与这两个寄存器进行核对，以保证操作系统和其他用户程序及数据不被该进程的运行所影响。</li><li><strong>整个系统中只有一个基地址寄存器（重定位寄存器）和一个界限寄存器（界地址寄存器）</strong></li></ul><p><em><strong>基址寄存器和界限寄存器完全实现了动态地址重定位+内存地址保护的所有功能</strong></em></p><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/Screen%20Shot%202022-07-24%20at%2013.54.21.png alt></p><h1 id=覆盖与交换>覆盖与交换<a hidden class=anchor aria-hidden=true href=#覆盖与交换>#</a></h1><p><strong>覆盖与交换技术是在多道程序环境下用来扩充内存的两种方法。</strong></p><h2 id=覆盖>覆盖<a hidden class=anchor aria-hidden=true href=#覆盖>#</a></h2><p><strong>早期的计算机系统中，主存容量很小，虽然主存中仅存放一道用户程序，但是存储空间放不下用户进程的现象也经常发生，这一矛盾可以用覆盖技术来解决。</strong></p><ul><li>早期内存扩充技术。用户需指定好各程序调入 memory 的先后次序。</li><li>覆盖的基本思想：<ul><li><strong>由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序），因此可以把用户空间分成一个固定区和若干个覆盖区。</strong></li><li>将经常活跃的部分放在固定区，其余部分按调用关系分段。首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。</li></ul></li></ul><p><em><strong>覆盖技术的特点是打破了必须将一个进程的全部信息装入主存后才能运行的限制，但当同时运行程序的代码量大于主存时仍不能运行。</strong></em></p><h2 id=交换>交换<a hidden class=anchor aria-hidden=true href=#交换>#</a></h2><ul><li><strong>将内存等待状态进程换出内存；将处于外存就绪态进程换入内存。</strong></li><li>交换的基本思想：<ul><li>把处于等待状态（或在 CPU 调度原则下被剥夺运行权利） 的程序从内存移到辅存，把内存空间腾出来，这一过程又叫换出；</li><li>把准备好竞争 CPU 运行的程序从辅存移到内存，这一过程又称为换入。[[2 进程管理#中级调度]]就是釆用交换技术。</li></ul></li><li>e.g.<ul><li>有一个 CPU 釆用时间片轮转调度算法的多道程序环境。时间片到，内存管理器将刚刚执行过的进程换出，将另一进程换入到刚刚释放的内存空间中。同时，CPU 调度器可以将时间片分配给其他已在内存中的进程。每个进程用完时间片都与另一进程交换。</li></ul></li></ul><p><strong>理想情况下，内存管理器的交换过程速度足够快，总有进程在内存中可以执行。</strong></p><ul><li>有关交换需要注意以下几个问题：<ul><li>交换需要备份存储，通常是快速磁盘。它必须足够大，并且提供对这些内存映像的直接访问。</li><li>为了有效使用 CPU，需要每个进程的执行时间比交换时间长，而影响交换时间的主要是转移时间。转移时间与所交换的内存空间成正比。</li><li>如果换出进程，必须确保该进程是完全处于空闲状态。</li><li>交换空间通常作为磁盘的一整块，且独立于文件系统，因此使用就可能很快。</li><li>交换通常在有许多进程运行且内存空间吃紧时开始启动，而系统负荷降低就暂停。</li><li>普通的交换使用不多，但交换策略的某些变种在许多系统中（如 UNIX 系统）仍发挥作用。</li></ul></li></ul><p><strong>交换技术主要是在不同进程（或作业）之间进行，而覆盖则用于同一个程序或进程中。</strong></p><ul><li><p><strong>只有请求调入和预调入能够实现大小不受内存容量限制的虚存</strong></p></li><li><p><em>Q：在这种情况下交换为什么不能实现虚存？</em></p><ul><li>交换不进行部分程序段或数据段的交换，其会交换整个进程。并且完成的部分交换也只是将受资源限制，暂时不能执行的程序段换出内存。</li><li>因此，虽然交换方式也能完成内存扩充任务，但无法实现自动覆盖，内外存统一管理。</li></ul></li><li><p><em><strong>即：虚存的本质意义在于 seamless 让用户和进程无感切换内外存。</strong></em></p></li></ul><p>由于覆盖技术要求给出程序段之间的覆盖结构，使得其对用户和程序员不透明，所以对于主存无法存放用户程序的矛盾，现代操作系统是通过虚拟内存技术来解决的，覆盖技术则已成为历史；而交换技术在现代操作系统中仍具有较强的生命力。</p><h1 id=内存连续分配管理>内存连续分配管理<a hidden class=anchor aria-hidden=true href=#内存连续分配管理>#</a></h1><p><strong>连续分配方式，是指为一个用户程序分配一个连续的内存空间。</strong> 它主要包括单一连续分配、固定分区分配和动态分区分配。</p><ul><li><p>进程是操作系统资源分配的最小单元。操作系统分配给进程的内存空间中包含五种段：数据段、代码段、BSS、堆、栈。</p></li><li><p><strong>数据段</strong>：</p><ul><li>存放程序中的静态变量</li><li>已初始化且不为零的全局变量。</li></ul></li><li><p><strong>代码段</strong>：</p><ul><li>存放可执行文件的操作指令，代码段是只读的，不可进行写操作。<em>这部分的区域在运行前已知其大小。</em></li></ul></li><li><p><strong>BSS 段( Block Started By Symbol)</strong>：</p><ul><li>存放未初始化的全局变量。在变量使用前由运行时初始化为零。</li></ul></li><li><p><strong>堆</strong>：</p><ul><li>存放进程运行中被<strong>动态分配的内存</strong>，其大小不固定。</li></ul></li><li><p><strong>栈</strong>：</p><ul><li>存放程序中的<strong>临时的局部变量</strong></li><li><strong>函数的参数值</strong>。</li></ul></li></ul><pre tabindex=0><code class=language-note-orange data-lang=note-orange>这就是为什么局部变量和全局变量有着本质区别的原因

局部变量作为临时信息存放在当前运行程序的栈中；全局变量则放置在数据段中。

由于运行过程中所产生的用户申请空间不固定，所以必须放在堆中：即可以随时方便扩容
</code></pre><p><a href=https://cloud.tencent.com/developer/news/682507>高频面试题——你真的搞懂物理内存与虚拟内存了吗 - 腾讯云开发者社区-腾讯云</a></p><h2 id=单一连续分配>单一连续分配<a hidden class=anchor aria-hidden=true href=#单一连续分配>#</a></h2><ul><li>内存在此方式下分为系统区和用户区，系统区仅提供给操作系统使用，通常在低地址部分；用户区是为用户提供的、除系统区之外的内存空间。</li><li>这种方式无需进行内存保护。</li><li>优缺点分析：<ul><li>这种方式的优点是简单、<strong>无外部碎片</strong>，可以釆用覆盖技术，不需要额外的技术支持。</li><li>缺点是只能用于单用户、单任务的操作系统中，有内部碎片，存储器的利用率极低。</li></ul></li></ul><h2 id=固定分区分配>固定分区分配<a hidden class=anchor aria-hidden=true href=#固定分区分配>#</a></h2><p><strong>固定分区分配是最简单的一种多道程序存储管理方式，它将用户内存空间划分为若干个固定大小的区域，每个分区只装入一道作业</strong>。当有空闲分区时，便可以再从外存的后备作业队列中,选择适当大小的作业装入该分区，如此循环。</p><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/Screen%20Shot%202022-07-24%20at%2014.04.25.png alt></p><ul><li><p>固定分区分配在划分分区时，有两种不同的方法。 ^a8d988</p><ul><li>分区大小相等：用于利用一台计算机去控制多个相同对象的场合，缺乏灵活性。</li><li>分区大小不等：划分为含有多个较小的分区、适量的中等分区及少量的大分区。</li></ul></li><li><p>为便于内存分配，通常将分区按大小排队，并为之建立一张<strong>分区说明表</strong>，其中各表项包括每个分区的起始地址、大小及状态（是否已分配）。当有用户程序要装入时，便检索该表，以找到合适的分区给予分配并将其状态置为”已分配”；未找到合适分区则拒绝为该用户程序分配内存。存储空间的分配情况。</p></li><li><p><strong>分区说明表</strong></p><ul><li><strong>OS 对内存的管理和控制通过分区说明表实现。</strong></li></ul></li></ul><blockquote><p>分区号、分区大小、起始地址和分区状态（是否空闲区）。
内存的分配实发、存储保护及地址变换都通过分区说明表实现。</p></blockquote><ul><li><p>这种分区方式存在两个问题：</p><ul><li>一是程序可能太大而放不进任何一个分区中，这时用户不得不使用覆盖技术来使用内存空间；</li><li>二是主存利用率低，当程序小于固定分区大小时，也占用了一个完整的内存分区空间，这样分区内部有空间浪费，这种现象称为<strong>内部碎片</strong>。</li><li><em>固定分区产生的是内部碎片。因为整体内存区域已经被完全分配完成，只有在每一个分配块的内部才会出现无法被利用的内容</em></li><li>[[#小结|碎片部分整理]]</li></ul></li><li><p>优缺点分析：</p><ul><li>优点：可用于多道程序设计的最简单存储分配。设计简单；无<strong>外部碎片</strong></li><li>缺点：内存利用率低，即使是小作业也要占用相同大小的分区；无法实现内存共享</li></ul></li><li><p>固定分区分配很少用于现在通用的操作系统中，但在某些用于控制多个相同对象的控制系统中仍发挥着一定的作用。</p></li></ul><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/Screen%20Shot%202022-07-24%20at%2014.05.49.png alt></p><h2 id=动态分区分配>动态分区分配<a hidden class=anchor aria-hidden=true href=#动态分区分配>#</a></h2><p>作业执行前不建立分区，<strong>分区的建立是在作业的处理过程中进行的</strong>。其大小可随作业或进程对内存的要求而改变。</p><ul><li>动态分区分配又称为可变分区分配，是一种动态划分内存的分区方法。</li><li><strong>这种分区方法不预先将内存划分，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此系统中分区的大小和数目是可变的。</strong></li></ul><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/Screen%20Shot%202022-07-24%20at%2014.06.48.png alt></p><pre tabindex=0><code>如图3-6所示，系统有64MB内存空间，其中低8MB固定分配给操作系统，其余为用户可用内存。开始时装入前三个进程，在它们分别分配到所需空间后，内存只剩下4MB，进程4无法装入。在某个时刻，内存中没有一个就绪进程，CPU出现空闲，操作系统就换出进程2，换入进程4。由于进程4比进程2小，这样在主存中就产生了一个6MB的内存块。之后CPU又出现空闲，而主存无法容纳进程2,操作系统就换出进程1，换入进程2。
</code></pre><ul><li><p><em>Q：如何进一步划分不合适的内存空闲区大小？</em></p><ul><li>如果分配的空闲区比所要求的大，则管理程序将该空闲区分成两个部分，其中一部分成为已分配区，而另一部分成为一个新的小空闲区。</li></ul></li><li><p>出现相应的内存分区管理：合并 拆分</p><ul><li>最先适应算法</li><li>最佳适应算法</li><li>最坏适应算法</li><li>临近适应算法</li></ul></li><li><p><em>动态分区算法会产生外部碎片。主要是由于每个可变的数据块之间是存在可以利用的部分的，通过一定的算法就可以进行外部碎片的重复利用。</em></p></li><li><p>动态分区在开始分配时是很好的，但是之后会导致内存中出现许多小的内存块。随着时间的推移，内存中会产生越来越多的碎片（图 3-6 中最后的 4MB 和中间的 6MB，且随着进程的换入/换出，很可能会出现更多更小的内存块)，内存的利用率随之下降。 ^38dde4</p></li><li><p><strong>这些小的内存块称为外部碎片，指在所有分区外的存储空间会变成越来越多的碎片，这与[[3 内存管理#固定分区分配|固定分区]]中的内部碎片正好相对。</strong></p></li><li><p>克服外部碎片可以通过<strong>紧凑（Compaction)技术</strong>来解决，就是操作系统不时地对进程进行移动和整理。</p><ul><li>但是这需要动态重定位寄存器的支持，且相对费时。</li><li>紧凑的过程实际上类似于 Windows 系统中的磁盘整理程序，只不过后者是对外存空间的紧凑。</li></ul></li><li><p><strong>内存紧缩</strong></p><ul><li>交换在内存中产生了多个空闲区(hole,也称为空洞),通过把所有的进程尽可能向下移动,有可能将这些小的空闲区合成一大块。</li><li>通常不会进行这个操作，因为其要消耗大量 CPU 时间</li></ul></li><li><p><em>Q：在交换时分配内存的大小是否固定？</em></p><ul><li>若是固定的情况，则分配很简单，只需进行精准分配即可。——即[[#固定分区分配|固定分区]]</li><li>但如果进程的数据段可以增长，那么在空间试图增长时，就会出现问题。——即动态分区<ul><li>一种简单的处理方法是：当换入或移动进程时为其分配一些额外的内存。且当进程被换出到磁盘上时不要计入这部分内容。</li></ul></li></ul></li></ul><p><strong>在进程装入或换入主存时，如果内存中有多个足够大的空闲块，操作系统必须确定分配哪个内存块给进程使用，这就是动态分区的分配策略</strong></p><ul><li><p><em><strong>从可用表或自由链中寻找空闲区的方法：</strong></em></p><ul><li><strong>首次适应 first fit</strong>——<em><strong>快 无需排序</strong></em><ul><li>空闲分区以地址递增的次序链接。分配内存时顺序查找，找到大小能满足要求的第一个空闲分区。</li><li><em>首次适配(first fit)算法。存储管理器沿着段链表进行搜索，直到找到一个足够大的空闲区，除非空闲区大小和要分配的空间大小正好一样，否则将该空闲区分为两部分，一部分供进程使用，另一部分形成新的空闲区。</em></li><li><strong>首次适配算法是一种速度很快的算法，因为它尽可能少地搜索链表结点。</strong></li></ul></li><li><strong>最佳适应 best fit</strong>——<em><strong>省 低地址充分利用</strong></em><ul><li>空闲分区按容量递增形成分区链，找到第一个能满足要求的空闲分区。<ul><li><em>最佳适配算法搜索整个链表（从开始到结束)，找出能够容纳进程的最小的空闲区。最佳适配算法试图找出最接近实际需要的空闲区，以最好地匹配请求和可用空闲区，而不是先拆分一个以后可能会用到的大的空闲区。</em></li></ul></li><li>保证了高地址有较大空间放置对内存要求多的进程或作业。找到最适应，但不一定会增加内存利用率。</li><li><strong>实际上其会造成比最佳适应算法更多的内存浪费</strong>：因为其会产生大量无用的小空闲区。</li></ul></li><li><strong>最坏适应 worst fit</strong>——<em><strong>志在消灭空闲碎片</strong></em><ul><li>又称最大适应(Largest Fit)算法，空闲分区以容量递减的次序链接。找到第一个能满足要求的空闲分区，也就是挑选出最大的分区。<ul><li>找到后划出要求长度，将余下部分合并（如果有相邻空闲存在）留在可用表中。</li></ul></li><li>期望分配后的剩余空间仍能进行再分配。</li></ul></li><li><strong>临近适配 next fit</strong>——<em><strong>first fit 的小改进</strong></em><ul><li>其工作方式与首次适配算法相同</li><li>不同点是每次找到合适的空闲区时都记录当时的位置，以便在下次寻找空闲区时从上次结束的地方开始搜索，而不用每次从头开始</li><li>性能略低于 first fit</li></ul></li><li><strong>快速适配 quick fit</strong><ul><li>其为常用大小的空闲区维护单独的链表</li></ul></li></ul></li><li><p><strong>不同方法性能分析</strong></p><ul><li>在这几种方法中，首次适应算法不仅是最简单的，而且通常也是最好和最快的。<ul><li>在 UNIX 系统的最初版本中，就是使用首次适应算法为进程分配内存空间，其中使用数组的数据结构 (而非链表）来实现。</li><li>不过，首次适应算法会使得内存的低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。</li></ul></li><li>邻近适应算法试图解决这个问题<ul><li>但实际上，它常常会导致在内存的末尾分配空间（因为在一遍扫描中，内存前面部分使用后再释放时，不会参与分配)，分裂成小碎片。</li><li>它通常比首次适应算法的结果要差。</li></ul></li><li>最佳适应算法虽然称为“最佳”，但是性能通常很差，因为每次最佳的分配会留下很小的难以利用的内存块，它会产生最多的外部碎片。</li><li>最坏适应算法与最佳适应算法相反，选择最大的可用块，这看起来最不容易产生碎片，但是却把最大的连续内存划分开，会很快导致没有可用的大的内存块，因此性能也非常差。</li></ul></li></ul><blockquote><p>Kunth 和 Shore 分别就前三种方法对内存空间的利用情况做了模拟实验，结果表明：</p><p>首次适应算法可能比最佳适应法效果好，而它们两者一定比最大适应法效果好。
另外注意,在算法实现时,分配操作中最佳适应法和最大适应法需要对可用块进行排序或遍历查找，而首次适应法和邻近适应法只需要简单查找；回收操作中，当回收的块与原来的空闲块相邻时（有三种相邻的情况，比较复杂)，需要将这些块合并。在算法实现时，使用数组或链表进行管理。
除了内存的利用率，这里的算法开销也是操作系统设计需要考虑的一个因素。</p></blockquote><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/Screen%20Shot%202022-07-24%20at%2014.15.44.png alt></p><h1 id=内存的非连续分配管理>内存的非连续分配管理<a hidden class=anchor aria-hidden=true href=#内存的非连续分配管理>#</a></h1><p><strong>非连续分配允许一个程序分散地装入到不相邻的内存分区中，根据分区的大小是否固定分为分页存储管理方式和分段存储管理方式。</strong></p><ul><li>分页存储管理方式中，又根据运行作业时是否要把作业的所有页面都装入内存才能运行分为<ul><li>基本分页存储管理方式</li><li>请求分页存储管理方式。</li></ul></li></ul><h2 id=分页管理>分页管理<a hidden class=anchor aria-hidden=true href=#分页管理>#</a></h2><p>固定分区会产生内部碎片，动态分区会产生外部碎片，这两种技术对内存的利用率都比较低。</p><p><strong>我们希望内存的使用能尽量避免碎片的产生，这就引入了分页的思想：把主存空间划分为大小相等且固定的块，块相对较小，作为主存的基本单位。每个进程也以块为单位进行划分，进程在执行时，以块为单位逐个申请主存中的块空间。</strong></p><ul><li><p>分页与[[#固定分区分配|固定分区管理]]的异同与联系</p><ul><li>分页的方法从形式上看，像分区相等的固定分区技术，分页管理不会产生外部碎片。</li><li>但它又有本质的不同点：块的大小相对分区要小很多，而且进程也按照块进行划分，进程运行时按块申请主存可用空间并执行。<ul><li>这样，进程只会在为最后一个不完整的块申请一个主存块空间时，才产生主存碎片，所以尽管会产生内部碎片，但是这种碎片相对于进程来说也是很小的，每个进程平均只产生半个块大小的内部碎片（也称页内碎片）。</li></ul></li></ul></li><li><p><em>Q：为什么引入分页技术？</em></p><ul><li>为了得到大的线性地址空间而不必购买更大的物理存储器</li></ul></li></ul><h3 id=分页>分页<a hidden class=anchor aria-hidden=true href=#分页>#</a></h3><ul><li><p>由程序产生的这些地址称为<strong>虚拟地址</strong>，它们构成了一个<strong>虚拟地址空间</strong></p><ul><li>在没有虚存的计算机上，系统直接将虚拟地址送到内存总线上，读写操作使用具有同样地址的物理内存字</li><li>在使用虚存的计算机上，虚拟地址不是被直接送到内存总线，而是被送到内存管理单元(Memory Management Unit, MMU) ，MMU 将虚拟地址映射为物理内存地址</li></ul></li><li><p>虚拟地址空间按照固定大小划分成被称为<strong>页面(page)</strong> 的若干单元。在物理内存中对应的单元称为<strong>页框(pageframe)</strong> 。外存也以同样的单位进行划分，直接称为<strong>块(Block)</strong>。</p><ul><li>页面和页框的大小通常是一样的。但通常也支持不同的页面大小混合使用的原则。<ul><li><code>如：若每个单元的大小均为 4KB，则对应于 64KB 的虚拟地址空间和 32KB 的物理内存——可得到 16 个虚拟页面和 8 个页框</code></li></ul></li><li>程在执行时需要申请主存空间，就是要为每个页面分配主存中的可用页框，这就产生了页和页框的一一对应。</li><li><strong>RAM 和磁盘之间的交换总是以整个页面为单元进行的</strong></li><li>为方便地址转换，页面大小应是 2 的整数幂。同时页面大小应该适中，如果页面太小，会使进程的页面数过多，这样页表就过长，占用大量内存，而且也会增加硬件地址转换的开销，降低页面换入/换出的效率；页面过大又会使页内碎片增大，降低内存的利用率。所以页面的大小应该适中。</li></ul></li></ul><p>==用户进程在页面间不再连续。实现了从连续到非连续管理的飞跃。为虚存的真正实现打下了基础。==</p><ul><li><strong>采用请求调页或预调页技术实现内外存统一管理。即实现了虚存</strong><ul><li>基于工作区的局部性原理建立。</li></ul></li></ul><p><strong>基本的分页+虚拟内存管理模型实例：</strong></p><pre tabindex=0><code>     MOV REG,0 

将虚拟地址0送到MMU。MMU看到虚拟地址落在页面0(0~4095)，根据其映射结果，这一页面对应的是页框2(8192~12287)，因此MMU把地址变换为8192，并把地址8192送到总线上。内存对MMU一无所知，它只看到一个读或写地址8192的请求并执行它。MMU从而有效地把所有从0~4095的虚拟地址映射到了8192~12287的物理地址。
</code></pre><pre tabindex=0><code>    MOV REG,8192  =====&gt; MOV REG,24576
</code></pre><pre tabindex=0><code>    MOV REG,20500+20  =====&gt; MOV REG,12288+20
</code></pre><p><strong>通过恰当地设置 MMU，可以将 16 个虚拟页面映射到 8 个页框中的任意一个</strong></p><ul><li><em>Q：但是这并没有解决虚拟地址空间比物理空间大的问题</em><ul><li>此时，拥有 8 个物理页框，也就意味着只能将 8 个存在的虚拟页面映射过去</li><li>其他的页面只能用一个 bit 设置 在/不在 位</li></ul></li></ul><p>当程序访问了一个未映射的页面：</p><pre tabindex=0><code>    MOV REG,32780  =====&gt; MOV REG,？？？？
</code></pre><ul><li><strong>缺页中断</strong><ul><li>虚拟页面 8（从 32768 开始） 的第 12 个字节所对应的物理地址是什么呢？MMU 注意到该页面没有被映射（在图中用叉号表示），于是使 CPU 陷入到操作系统，这个陷阱称为<strong>缺页中断或缺页错误(page fault)</strong>。操作系统找到一个很少使用的页框且把它的内容写入磁盘（如果它不在磁盘上)。<ul><li>随后把需要访问的页面读到刚才回收的页框中，修改映射关系，然后重新启动引起陷阱的指令。</li></ul></li></ul></li></ul><p><strong>地址结构构造</strong></p><pre tabindex=0><code>    输入的16位虚拟地址：|0|0|1|0|0|0|0|0|0|0|0|0|0|1|0|0|
</code></pre><p>中间过程通过查找页表：001 变页表中查到的 110；而后面的偏移量不变<a href=marginnote3app://note/6FA39083-88DC-4582-B58E-0D0579E83D75></a></p><pre tabindex=0><code>    输出的16位虚拟地址：|1|1|0|0|0|0|0|0|0|0|0|0|0|1|0|0|
</code></pre><table><thead><tr><th>4 位页号</th><th>12 位偏移量</th></tr></thead><tbody><tr><td>可以表示 16 个页面</td><td>可以为一页内的全部 4096 个字节编址</td></tr></tbody></table><ul><li>通常，可以用页号作为页表的索引，以得出对应于该虚拟页面的页框号：<ul><li>在/不在 位是 0，则将引起一个 OS 陷阱</li><li>若该位是 1，则将在页表中查到的页框号复制到输出 Reg 的高 3 位中，再加上输入虚拟地址中的 12 位偏移量，如此就构成了 15 位的物理地址。</li><li>输出 reg 的内容随即被作为物理地址送到内存总线</li></ul></li></ul><h3 id=页表>页表<a hidden class=anchor aria-hidden=true href=#页表>#</a></h3><p>为了便于在内存中找到进程的每个页面所对应的物理块，系统为每个进程建立一张页表，记录页面在内存中对应的物理块号，页表一般存放在内存中。</p><ul><li><strong>作为一种最简单的实现，虚拟地址到物理地址的映射可以概括如下：虚拟地址被分成虚拟页号（高位部分)和偏移量（低位部分）两部分。</strong><ul><li>例如，对于 16 位地址和 4KB 的页面大小，高 4 位可以指定 16 个虚拟页面中的一页，而低 12 位接着确定了所选页面中的字节偏移量(0~4095)。但是使用 3 或者 5 或者其他位数拆分虚拟地址也是可行的。不同的划分对应不同的页面大小。</li></ul></li><li>虚拟页号可用作页表的索引,以找到该虚拟页面对应的页表项。</li><li>由页表项可以找到页框号。然后把页框号拼接到偏移量的高位端，以替换掉虚拟页号，形成送往内存的物理地址</li></ul><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/Screen%20Shot%202022-07-24%20at%2014.26.25.png alt></p><ul><li><p><em><strong>页表的目的是把虚拟页面映射为页框</strong></em></p><ul><li>从数学角度上讲，页表就是一个函数，其参数是虚拟页号，结果是物理页框号。</li><li>通过这个函数可以把虚拟地址中的虚拟页面域替换成页框域，从而形成物理地址</li><li><em>在配置了页表后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号。可见，页表的作用是实现从页号到物理块号的地址映射</em></li></ul></li><li><p>为了方便 CPU 高效执行管理物理内存，每一次都需要从虚拟内存中拿一个页的代码放到物理内存。虚拟内存页有三种状态，分别是未分配、已缓存和未缓存状态。</p><ul><li><strong>未分配：</strong> 指的是未被操作系统分配或者创建的，未分配的虚拟页不存在任何数据和代码与它们关联，因此不占用磁盘资源；</li><li><strong>已缓存：</strong> 表示的是物理内存中已经为该部分分配的，存在虚拟内存和物理内存映射关系的；——即 DRAM</li><li><strong>未缓存：</strong> 指的是已经加载到虚拟内存中的，但是未在物理内存中建立映射关系的</li></ul></li><li><p>利用页表实现对更大虚拟地址空间的映射：</p><ul><li><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/202208031537077.png alt></li></ul></li></ul><h3 id=地址变换机构-mmu>地址变换机构 MMU<a hidden class=anchor aria-hidden=true href=#地址变换机构-mmu>#</a></h3><p><em><strong>地址变换机构的任务是将逻辑地址转换为内存中物理地址，地址变换是借助于页表实现的。</strong></em></p><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/Screen%20Shot%202022-07-24%20at%2014.27.59.png alt></p><ul><li><strong>在系统中通常设置一个页表寄存器(PTR)，存放页表在内存的始址 F 和页表长度 M</strong>。<ul><li>进程未执行时，页表的始址和长度存放在进程控制块中</li><li>当进程执行时，才将页表始址和长度存入页表寄存器。</li></ul></li></ul><pre tabindex=0><code>设页面大小为L，逻辑地址A到物理地址E的变换过程如下：

1.  计算页号P(P=A/L)和页内偏移量W (W=A%L)。
2.  比较页号P和页表长度M，若P &gt;= M，则产生越界中断，否则继续执行。
3.  页表中页号P对应的页表项地址 = 页表起始地址F + 页号P * 页表项长度，取出该页表项内容b，即为物理块号。
4.  计算E=b*L+W，用得到的物理地址E去访问内存。

例如，若页面大小L为1K字节，页号2对应的物理块为b=8，计算逻辑地址A=2500 的物理地址E的过程如下：P=2500/1K=2，W=2500%1K=452，查找得到页号2对应的物理块的块号为 8，E=8*1024+452=8644。
</code></pre><p>以上整个地址变换过程均是由硬件自动完成的。</p><ul><li>下面讨论分页管理方式存在的两个主要问题：<ul><li><em>每次访存操作都需要进行逻辑地址到物理地址的转换，地址转换过程必须足够快，否则访存速度会降低；</em>——<strong>TLB</strong></li><li><em>每个进程引入了页表，用于存储映射机制，页表不能太大，否则内存利用率会降低。</em>——<strong>多级页表</strong></li></ul></li></ul><h3 id=tlb>TLB<a hidden class=anchor aria-hidden=true href=#tlb>#</a></h3><p>在任何分页系统中，都需要考虑两个主要问题：</p><ol><li><strong>虚拟地址到物理地址的映射必须非常快</strong></li><li><strong>如果虚拟地址空间很大，页表也会非常大</strong></li></ol><ul><li><p>第一个问题是由于每次访问内存都需要进行虚拟地址到物理地址的映射，所有的指令最终都必须来自内存，并且很多指令也会访问内存中的操作数</p></li><li><p>第二个问题来自现代计算机至少使用 32 位的虚拟地址。假设 32 位系统，则其地址空间将有 100 万页。如果虚拟地址空间中有 100 万页，那么页表必然有 100 万条表项。</p><ul><li>并且每个进程都有自己的页表。因为它有自己的虚拟地址空间</li></ul></li><li><p>对大而快速的页顶映射的需求成为构建计算机的重要约束。最简单的设计（至少从概念上）是使用由“<strong>快速硬件寄存器</strong>”阵列组成的单一页表，每一个表项对应一个虚拟页面，虚拟页号作为索引</p><ul><li>当启动一个进程时，操作系统把保存在内存中的进程页表的副本载入到寄存器中。在进程运行过程中，不必再为页表而访问内存。</li><li>这个方法的优势是简单并且在映射过程中不需要访问内存。</li><li>而缺点是在页表很大时，代价高昂。而且每一次上下文切换都必须装载整个页表，这样会降低性能。</li></ul></li><li><p>大多数的优化技术都是从内存中的页表开始的。这种设计对效率有巨大的影响</p><ul><li>在不分页情况下，这条指令只访存一次：即从内存中取指令</li><li>在分页机制下，会因为要访问页表而引起更多次的内存访问。</li></ul></li></ul><p>解决方案则是建立在这样一种观察：<strong>大多数程序总是对少量页面进行多次的访问，而不是相反。</strong>——即[[#工作集|工作集背后的局部性原理]]</p><p>上面提到的解决方案是为计算机设置一个小型的硬件设备,将虚拟地址直接映射到物理地址,而不必再访问页表。——即 TLB</p><ul><li><p><strong>转换检测缓冲区 Translation Lookaside Buffer, TLB</strong></p><ul><li><em><strong>本质就是一张小型的页表</strong></em></li><li>又被称为相联存储器，或快表</li><li>它通常在 MMU 中，仅包含少量的表项，很少会超过 256 个——<strong>表大小得到控制</strong></li><li>每个表项纪录了一个页面的相关信息，包括虚拟页号、页面修改位、保护码以及该页对应的物理页框</li></ul></li><li><p><strong>TLB 工作原理</strong></p><ul><li>将一个虚拟地址放入 MMU 中进行转换时，硬件首先通过将该虚拟页号与 TLB 中所有表项同时（即并行）进行匹配，<strong>判断虚拟页面是否在其中。</strong></li><li>如果发现了一个有效的匹配并且要进行的访问操作并不违反保护位， <strong>则将页框号直接从 TLB 中取出而不必再访问页表。</strong></li><li><em>Q：当虚拟页号不在 TLB 中会怎样？</em><ul><li>若 MMU 检测到没有匹配项，就会进行正常的页表检查</li><li>接着从 TLB 中淘汰一个表项，然后用新的页表项代替它。</li><li>这样,如果这一页面很快被再次访问,第二次访间 TLB 时自然将会命中而不是未命中。<ul><li>当一个表项被清除出 TLB 时,将修改位复制到内存中的页表项,而除了访问位,其他的值不变。当页表项中从页表中装入 TLB 中时,所有的值都来自内存。</li></ul></li></ul></li></ul></li></ul><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/Screen%20Shot%202022-07-24%20at%2014.32.10.png alt></p><ul><li><p>在具有快表的分页机制中，地址的变换过程：</p><ul><li>CPU 给出逻辑地址后，由硬件进行地址转换并将页号送入高速缓存寄存器，并将此页号与快表中的所有页号进行比较。</li><li>如果找到匹配的页号，说明所要访问的页表项在快表中，则直接从中取出该页对应的页框号，与页内偏移量拼接形成物理地址。这样，存取数据仅一次访存便可实现。</li><li>如果没有找到，则需要访问主存中的页表，在读出页表项后，应同时将其存入快表，以便后面可能的再次访问。但若快表已满，则必须按照一定的算法对旧的页表项进行替换。</li></ul></li><li><p>注意：有些处理机设计为快表和慢表同时查找，如果在快表中查找成功则终止慢表的查找。</p></li></ul><p><strong>在这种设计中，对 TLB 的管理和 TLB 的失效处理都完全由 MMU 硬件来实现。只有在内存中没有找到某个页面时，才会陷入到操作系统中。</strong></p><p>而如果当 TLB 大到一定程度可以减少是效率时，TLB 的软件管理就会变的足够有效。这种方法的好处是获得了一个非常简单的 MMU。而这就在片上为高速缓存以及其他性能改善腾出了空间。</p><ul><li><strong>使用软件管理 TLB 时的两种失效</strong><ul><li><strong>软失效</strong>——仅在内存范围内处理<ul><li>即一个页面访问在内存中而不在 TLB 中。</li><li>此时需要做的就是更新 TLB，无需产生磁盘 IO</li></ul></li><li><strong>硬失效</strong>——与外围磁盘 IO 有关<ul><li>此刻需要一次磁盘存取以装入该页面，需要高达 ms 级别的时间</li><li>硬失效的处理时间往往是软失效的百万倍</li></ul></li><li>在页表中进行查找相应的映射被称为<strong>页表遍历</strong></li></ul></li></ul><p>一般快表的命中率可以达到 90% 以上，这样，分页带来的速度损失就降低到 10% 以下。快表的有效性是基于著名的局部性原理，这在后面的虚拟内存中将会具体讨论。</p><h3 id=多级页表>多级页表<a hidden class=anchor aria-hidden=true href=#多级页表>#</a></h3><p><em><strong>——即针对大内存的页表</strong></em></p><ul><li><p><strong>引入多级页表的原因是避免把全部页表一直保存在内存中。</strong></p><ul><li>特别是那些从不需要的页表就不应该保留：比如一个需要 12MB 内存的进程，其最底端是 4MB 的程序正文段，后面是 4MB 的数据段，顶端是 4MB 的堆栈段——在数据段上方和数据段下方之间是大量根本没有使用的空闲区</li></ul></li><li><p>将页表映射的思想进一步延伸，就可以得到二级分页：</p><ul><li>将页表的 10 页空间也进行地址映射，建立上一级页表，用于存储页表的映射关系。这里对页表的 10 个页面进行映射只需要 10 个页表项，所以上一级页表只需要 1 页就足够（可以存储 2^10=1024 个页表项）。</li><li>在进程执行时，只需要将这 1 页的上一级页表调入内存即可，进程的页表和进程本身的页面，可以在后面的执行中再调入内存。</li></ul></li></ul><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/Screen%20Shot%202022-07-24%20at%2014.35.43.png alt></p><pre tabindex=0><code>举例，32位系统中进程分页的工作过程：假定内核已经给一个正在运行的进程分配的逻辑地址空间是0x20000000到0x2003FFFF，这个空间由64个页面组成。在进程运行时，我们不需要知道全部这些页的页框的物理地址，很可能其中很多页还不在主存中。这里我们只注意在进程运行到某一页时，硬件是如何计算得到这一页的页框的物理地址即可。现在进程需要读逻辑地址0x20021406中的字节内容，这个逻辑地址按如下进行处理：  
    逻辑地址： 0x20021406 (0010 0000 0000 0010 0001 0100 0000 0110 B)  
    顶级页表字段：0x80 (00 1000 0000 B)  
    二级页表字段：0x21 (00 0010 0001B)  
    页内偏移量字段：0x406  (0100 0000 0110 B)  
  
顶级页表字段的0x80用于选择顶级页表的第0x80表项，此表项指向和该进程的页相关的二级页表；二级页表字段0x21用于选择二级页表的第0x21表项，此表项指向包含所需页的页框；最后的页内偏移量字段0x406用于在目标页框中读取偏移量为0x406中的字节。  
  
这是32位系统下比较实际的一个例子。看似较为复杂的例子，有助于比较深入地理解，希望读者能自己动手计算一遍转换过程。
</code></pre><ul><li><em><strong>建立多级页表的目的在于建立索引</strong></em>，这样不用浪费主存空间去存储无用的页表项，也不用盲目地顺序式查找页表项，<strong>而建立索引的要求是最高一级页表项不超过一页的大小</strong>。在 64 位操作系统中，页表的划分则需要重新考虑，这是很多教材和辅导书中的常见题目，但是很多都给出了错误的分析，需要注意。</li></ul><pre tabindex=0><code>我们假设仍然釆用4KB页面大小。偏移量字段12位，假设页表项大小为8B。这样，其上一级分页时，每个页框只能存储29(4KB/8B)个页表项，而不再是210个，所以上一级页表字段为9位。后面同理继续分页。64=12+9+9+9+9+9+7，所以需6级分页才能实现索引。很多书中仍然按4B页表项分析，虽然同样得出6级分页的结果，但显然是错误的。这里给出两个实际的64位操作系统的分页级别（注意：里面没有使用全部64位寻址，不过由于地址字节对齐的设计考虑，仍然使用8B大小的页表项），理解了表3-2中的分级方式，相信对多级分页就非常清楚了。
</code></pre><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/Screen%20Shot%202022-07-24%20at%2014.37.02.png alt></p><h2 id=分段管理>分段管理<a hidden class=anchor aria-hidden=true href=#分段管理>#</a></h2><p>分页管理方式是从计算机的角度考虑设计的，以提高内存的利用率，提升计算机的性能, 且分页通过硬件机制实现，对用户完全透明；</p><p><strong>而分段管理方式的提出则是考虑了用户和程序员，以满足方便编程、信息保护和共享、动态增长及动态链接等多方面的需要。</strong></p><ul><li><em>Q：为什么需要分段？</em><ul><li>对许多问题来说，有两个或多个独立的地址空间可能比只有一个要好得多。<ul><li>比如，一个编译器在编译过程中会建立许多表，其中可能包括：<ul><li>被保存起来的源程序正文</li><li>符号表，包含变量的名字和属性</li><li>包含用到的所有整型量和浮点常量的表</li><li>语法分析树。包含程序语法分析的结果</li><li>编译器内部过程调用使用的堆栈。</li></ul></li><li>地址空间不足问题<ul><li>在这种情况下，如果一个程序中的变量数量要远比其他部分多的时候。地址空间中分配给符号表的块可能会被装满，但这时其他表中还有大量的空间</li></ul></li></ul></li></ul></li></ul><h3 id=分段>分段<a hidden class=anchor aria-hidden=true href=#分段>#</a></h3><p>段式管理方式按照用户进程中的自然段划分逻辑空间。例如，用户进程由主程序、两个子程序、栈和一段数据组成，于是可以把这个用户进程划分为 5 个段，每段从 0 开始编址，并分配一段连续的地址空间（段内要求连续，段间不要求连续，因此整个作业的地址空间是二维的）。其逻辑地址由段号 S 与段内偏移量 W 两部分组成。</p><ul><li><strong>分段</strong><ul><li>在机器上提供多个互相独立的称为段(segment)的地址空间。</li><li>分段是指在用户编程时，将程序按照逻辑划分为几个逻辑段</li><li><strong>段</strong> 基本性质<ul><li>每个段由一个从 0 到最大的线性地址序列构成</li><li>各个段的长度可以是 0 到最大值间任意值</li><li>不同段长度可以不同，并且通常也不会相同</li><li>段的长度在运行期间可以动态改变</li></ul></li><li>段是一个逻辑实体<ul><li>可包括一个过程、一个数组、一个堆栈、一组数值变量。但不会包含不同类型的内容。</li></ul></li></ul></li></ul><table><thead><tr><th>段号</th><th>段内偏移量</th></tr></thead><tbody><tr><td>31&mldr;16</td><td>15&mldr;0</td></tr></tbody></table><p><code>段号为 16 位，段内偏移量为 16 位，则一个作业最多可有 2^16=65536 个段，最大段长为 64KB。</code></p><ul><li>在页式系统中，逻辑地址的页号和页内偏移量对用户是透明的，<strong>但在段式系统中，段号和段内偏移量必须由用户显示提供，在髙级程序设计语言中，这个工作由编译程序完成。</strong></li></ul><hr><p><strong>段表</strong></p><ul><li>每个进程都有一张逻辑空间与内存空间映射的段表，其中每一个段表项对应进程的一个段，段表项记录该段在内存中的起始地址和段的长度。</li></ul><table><thead><tr><th>段号</th><th>段长</th><th>本段在主存的起始地址</th></tr></thead></table><ul><li>在配置了段表后，执行中的进程可通过查找段表，找到每个段所对应的内存区。可见，段表用于实现从逻辑段到物理内存区的映射</li></ul><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/Screen%20Shot%202022-07-24%20at%2014.43.14.png alt></p><ul><li><p>对于地址空间不足问题的解决-即<strong>分段管理优势 1：对地址空间的更灵活利用</strong></p><ul><li>因为每个段都构成了一个独立的地址空间,所以它们可以独立地增长或减小而不会影响到其他的段。</li><li>如果一个在某个段中的堆栈需要更多的空间,它就可以立刻得到所需要的空间,因为它的地址空间中没有任何其他东西阻挡它增长。</li><li><em><strong>页式存储管理只有内部碎片；段式存储管理只有外部碎片</strong></em></li><li><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/202207162143949.png alt></li></ul></li><li><p><strong>分段管理优势 2：对编译链接的过程优化</strong></p><ul><li>把单独编译好的过程链接起来的操作可以得到很大的简化</li><li>在一维地址中：过程被像数组中元素一样紧贴排列。因此修改一个过程的大小会影响到其他无关过程的起始地址。开销非常巨大</li><li>而在二维地址中：对段 n 过程的调用将使用两部分组成的地址 <code>(n,0)</code> 来寻址到字 0 入口点</li></ul></li><li><p><strong>分段管理优势 3：便于进程间共享过程和数据</strong></p><ul><li>最常见的例子就是共享库</li><li>在分段系统中，可以把图形库放到一个单独的段中供各个进程共享，从而不需要在每个进程的地址空间单独保存一份。</li><li>单纯的分页系统中也可以实现共享库的功能，但实际上要复杂很多，并且还是通过模拟分段实现的</li><li><em>段的共享是通过两个作业的段表中相应表项指向被共享的同一个物理副本实现的。，因此在内存中仅仅保存一份段S的内容。此时物理段号相同，但逻辑段号根据每个进程本身决定</em></li></ul></li></ul><h3 id=地址变换机构-mmu-1>地址变换机构 MMU<a hidden class=anchor aria-hidden=true href=#地址变换机构-mmu-1>#</a></h3><p>分段系统的地址变换过程如图 3-15 所示。为了实现进程从逻辑地址到物理地址的变换功能，在系统中设置了段表寄存器，用于存放段表始址 F 和段表长度 M。其从逻辑地址 A 到物理地址 E 之间的地址变换过程如下：</p><pre tabindex=0><code>-   从逻辑地址A中取出前几位为段号S，后几位为段内偏移量W。
-   比较段号S和段表长度M，若S多M，则产生越界中断，否则继续执行。
-   段表中段号S对应的段表项地址 = 段表起始地址F + 段号S * 段表项长度，取出该段表项的前几位得到段长C。若段内偏移量&gt;=C，则产生越界中断，否则继续执行。
-   取出段表项中该段的起始地址b，计算 E = b + W，用得到的物理地址E去访问内存。
</code></pre><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/Screen%20Shot%202022-07-24%20at%2014.44.08.png alt></p><h3 id=段的共享与保护>段的共享与保护<a hidden class=anchor aria-hidden=true href=#段的共享与保护>#</a></h3><ul><li><p>在分段系统中，段的共享是通过两个作业的段表中相应表项指向被共享的段的同一个物理副本来实现的。</p></li><li><p>当一个作业正从共享段中读取数据时，必须防止另一个作业修改此共享段中的数据。不能修改的代码称为纯代码或可重入代码（它不属于临界资源)，这样的代码和不能修改的数据是可以共享的，而可修改的代码和数据则不能共享。</p></li><li><p>与分页管理类似，分段管理的保护方法主要有两种：</p><ul><li>一种是存取控制保护，另一种是地址越界保护。地址越界保护是利用段表寄存器中的段表长度与逻辑地址中的段号比较，若段号大于段表长度则产生越界中断；再利用段表项中的段长和逻辑地址中的段内位移进行比较，若段内位移大于段长，也会产生越界中断。</li></ul></li></ul><h2 id=段页式管理>段页式管理<a hidden class=anchor aria-hidden=true href=#段页式管理>#</a></h2><p><strong>页式存储管理能有效地提高内存利用率，而分段存储管理能反映程序的逻辑结构并有利于段的共享。如果将这两种存储管理方法结合起来，就形成了段页式存储管理方式。</strong></p><p><strong>如果一个段比较大，把它整个保存在内存中可能很不方便甚至是不可能的，因此产生了对它进行分页的想法。这样，只有那些真正需要的页面才会被调入内存。</strong>——<em>使用段页式存储管理的原因</em></p><p><em><strong>段页式管理的本质：对段进行分页操作</strong></em></p><ul><li>在段页式系统中，作业的地址空间首先被分成若干个逻辑段，每段都有自己的段号，然后再将每一段分成若干个大小固定的页。对内存空间的管理仍然和分页存储管理一样，将其分成若干个和页面大小相同的存储块，对内存的分配以存储块为单位</li></ul><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/Screen%20Shot%202022-07-24%20at%2014.50.31.png alt></p><p>在段页式系统中，作业的逻辑地址分为三部分：段号、页号和页内偏移量</p><table><thead><tr><th>段号 S</th><th>页号 P</th><th>页内偏移量 W</th></tr></thead></table><ul><li>==为了实现地址变换，<strong>系统为每个进程建立一张段表</strong>，而每个分段有一张页表。==<ul><li>段表表项中至少包括段号、页表长度和页表起始地址，页表表项中至少包括页号和块号。此外，系统中还应有一个段表寄存器，指出作业的段表起始地址和段表长度。</li></ul></li><li><strong>注意：在一个进程中，段表只有一个，而页表可能有多个。</strong></li><li>在进行地址变换时，首先通过段表查到页表起始地址，然后通过页表找到页帧号，最后形成物理地址。<ul><li><strong>进行一次访问实际需要三次访问主存</strong>，这里同样可以使用快表以加快查找速度，其关键字由段号、页号组成，值是对应的页帧号和保护码。</li></ul></li></ul><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/Screen%20Shot%202022-07-24%20at%2014.52.37.png alt></p><h1 id=2-虚拟内存管理>2 虚拟内存管理<a hidden class=anchor aria-hidden=true href=#2-虚拟内存管理>#</a></h1><p><strong>传统存储管理方式的特征</strong>
上一节所讨论的各种内存管理策略都是为了同时将多个进程保存在内存中以便允许多道程序设计。它们都具有以下两个共同的特征：</p><ul><li>一次性<ul><li>作业必须一次性全部装入内存后，方能开始运行。这会导致两种情况发生：<ul><li>当作业很大，不能全部被装入内存时，将使该作业无法运行；</li><li>当大量作业要求运行时，由于内存不足以容纳所有作业，只能使少数作业先运行，导致多道程序度的下降。</li></ul></li></ul></li><li>驻留性<ul><li>作业被装入内存后，就一直驻留在内存中，其任何部分都不会被换出，直至作业运行结束。运行中的进程，会因等待 I/O 而被阻塞，可能处于长期等待状态。</li><li>由以上分析可知，许多在程序运行中不用或暂时不用的程序（数据）占据了大量的内存空间，而一些需要运行的作业又无法装入运行，显然浪费了宝贵的内存资源。</li></ul></li></ul><h2 id=局部性原理>局部性原理<a hidden class=anchor aria-hidden=true href=#局部性原理>#</a></h2><p>要真正理解虚拟内存技术的思想，首先必须了解计算机中著名的局部性原理。</p><blockquote><p>著名的 Bill Joy (SUN 公司 CEO)说过：”在研究所的时候，我经常开玩笑地说高速缓存是计算机科学中唯一重要的思想。事实上，髙速缓存技术确实极大地影响了计算机系统的设计。“快表、 页高速缓存以及虚拟内存技术从广义上讲，都是属于高速缓存技术。这个技术所依赖的原理就是局部性原理。局部性原理既适用于程序结构，也适用于数据结构（更远地讲，Dijkstra 著名的关于“goto 语句有害”的论文也是出于对程序局部性原理的深刻认识和理解）。</p></blockquote><ul><li>局部性原理表现在以下两个方面：<ul><li><strong>时间局部性</strong>：<ul><li>如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。</li></ul></li><li><strong>空间局部性</strong>：<ul><li>一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。</li></ul></li></ul></li></ul><p>时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。</p><p><strong>虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。</strong></p><h2 id=虚存的定义和特征>虚存的定义和特征<a hidden class=anchor aria-hidden=true href=#虚存的定义和特征>#</a></h2><ul><li>基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其余部分留在外存，就可以启动程序执行。</li><li>在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存,然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换出到外存上，从而腾出空间存放将要调入内存的信息。<strong>这样，系统好像为用户提供了一个比实际内存大得多的存储器，称为虚拟存储器。</strong></li></ul><p><strong>之所以将其称为虚拟存储器，是因为这种存储器实际上并不存在，只是由于系统提供了部分装入、请求调入和置换功能后（对用户完全透明），给用户的感觉是好像存在一个比实际物理内存大得多的存储器</strong>。</p><ul><li>虚拟存储器的大小由计算机的地址结构决定，并非是内存和外存的简单相加。虚拟存储器有以下三个主要特征：<ul><li><strong>多次性</strong><ul><li>是指无需在作业运行时一次性地全部装入内存，而是允许被分成多次调入内存运行。</li></ul></li><li><strong>对换性</strong><ul><li>是指无需在作业运行时一直常驻内存，而是允许在作业的运行过程中，进行换进和换出。</li></ul></li><li><strong>虚拟性</strong><ul><li>是指从逻辑上扩充内存的容量，使用户所看到的内存容量，远大于实际的内存容量。</li></ul></li></ul></li></ul><h2 id=虚存技术的实现>虚存技术的实现<a hidden class=anchor aria-hidden=true href=#虚存技术的实现>#</a></h2><ul><li><p>虚拟内存中，允许将一个作业分多次调入内存。釆用连续分配方式时，会使相当一部分内存空间都处于暂时或“永久”的空闲状态，造成内存资源的严重浪费，而且也无法从逻辑上扩大内存容量。因此，虚拟内存的实需要建立在离散分配的内存管理方式的基础上。</p></li><li><p>虚拟内存的实现有以下三种方式：</p><ul><li>请求分页存储管理。</li><li>请求分段存储管理。</li><li>请求段页式存储管理。</li></ul></li><li><p>不管哪种方式，都需要有一定的硬件支持。一般需要的支持有以下几个方面：</p><ul><li><strong>一定容量的内存和外存</strong>。</li><li><strong>页表机制（或段表机制），作为主要的数据结构</strong>。</li><li><strong>中断机构</strong>，当用户程序要访问的部分尚未调入内存，则产生中断。</li><li><strong>地址变换机构</strong>，逻辑地址到物理地址的变换。</li></ul></li></ul><h1 id=请求页式管理实现虚存>请求页式管理实现虚存<a hidden class=anchor aria-hidden=true href=#请求页式管理实现虚存>#</a></h1><p><strong>请求分页系统建立在基本分页系统基础之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。</strong></p><p><strong>请求分页是目前最常用的一种实现虚拟存储器的方法。</strong></p><ul><li>在请求分页系统中，只要求将当前需要的一部分页面装入内存，便可以启动作业运行。在作业执行过程中，当所要访问的页面不在内存时，再通过调页功能将其调入，同时还可以通过置换功能将暂时不用的页面换出到外存上，以便腾出内存空间。</li><li>为了实现请求分页，系统必须提供一定的硬件支持。除了需要一定容量的内存及外存的计算机系统，还需要有页表机制、缺页中断机构和地址变换机构。</li></ul><h2 id=页表机制>页表机制<a hidden class=anchor aria-hidden=true href=#页表机制>#</a></h2><p>请求分页系统的页表机制不同于基本分页系统，请求分页系统在一个作业运行之前不要求全部一次性调入内存，因此在作业的运行过程中，必然会出现要访问的页面不在内存的情况，如何发现和处理这种情况是请求分页系统必须解决的两个基本问题。为此，在请求页表项中增加了四个字段</p><table><thead><tr><th>页号</th><th>物理块号</th><th>状态位 P</th><th>访问字段 A</th><th>修改位 M</th><th>外存地址</th></tr></thead></table><p>增加的四个字段说明如下：</p><ul><li>状态位 P：用于指示该页是否已调入内存，供程序访问时参考。</li><li>访问字段 A：用于记录本页在一段时间内被访问的次数，或记录本页最近己有多长时间未被访问，供置换算法换出页面时参考。</li><li>修改位 M：标识该页在调入内存后是否被修改过。</li><li>外存地址：用于指出该页在外存上的地址，通常是物理块号，供调入该页时参考。</li></ul><h2 id=缺页中断机构>缺页中断机构<a hidden class=anchor aria-hidden=true href=#缺页中断机构>#</a></h2><ul><li><p>在请求分页系统中，每当所要访问的页面不在内存时，便产生一个缺页中断，请求操作系统将所缺的页调入内存。此时应将缺页的进程阻塞（调页完成唤醒)，如果内存中有空闲块，则分配一个块，将要调入的页装入该块，并修改页表中相应页表项，若此时内存中没有空闲块，则要淘汰某页（若被淘汰页在内存期间被修改过，则要将其写回外存)。</p></li><li><p>缺页中断作为中断同样要经历，诸如保护 CPU 环境、分析中断原因、转入缺页中断处理程序、恢复 CPU 环境等几个步骤。但与一般的中断相比，它有以下两个明显的区别：</p><ul><li>在指令执行期间产生和处理中断信号，而非一条指令执行完后，属于内部中断。</li><li>一条指令在执行期间，可能产生多次缺页中断。</li></ul></li></ul><h2 id=地址变换机构>地址变换机构<a hidden class=anchor aria-hidden=true href=#地址变换机构>#</a></h2><p>请求分页系统中的地址变换机构，是在分页系统地址变换机构的基础上，为实现虚拟内存，又增加了某些功能而形成的。</p><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/Screen%20Shot%202022-07-24%20at%2015.03.27.png alt></p><ul><li>在进行地址变换时，先检索 TLB：<ul><li>若找到要访问的页，便修改页表项中的访问位（写指令则还须重置修改位)，然后利用页表项中给出的物理块号和页内地址形成物理地址。</li><li><strong>若未找到该页的页表项，应到内存中去查找页表</strong>，再对比页表项中的状态位 P，看该页是否已调入内存，未调入则产生缺页中断，请求从外存把该页调入内存。</li></ul></li></ul><h1 id=页面置换算法>页面置换算法<a hidden class=anchor aria-hidden=true href=#页面置换算法>#</a></h1><p>进程运行时，若其访问的页面不在内存而需将其调入，但内存已无空闲空间时，就需要从内存中调出一页程序或数据，送入磁盘的对换区。</p><p><strong>选择调出页面的算法就称为页面置换算法。好的页面置换算法应有较低的页面更换频率，也就是说，应将以后不会再访问或者以后较长时间内不会再访问的页面先调出。</strong></p><h2 id=最佳置换算法-opt>最佳置换算法 OPT<a hidden class=anchor aria-hidden=true href=#最佳置换算法-opt>#</a></h2><p><strong>最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。</strong></p><p>但由于人们目前无法预知进程在内存下的若干页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。</p><ul><li><strong>最佳置换算法可以用来评价其他算法。</strong></li></ul><pre tabindex=0><code>假定系统为某进程分配了三个物理块，并考虑有以下页面号引用串：  
    7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1  
  
进程运行时，先将7, 0, 1三个页面依次装入内存。进程要访问页面2时，产生缺页中断，根据最佳置换算法，选择第18次访问才需调入的页面7予以淘汰。然后，访问页面0时，因为已在内存中所以不必产生缺页中断。访问页面3时又会根据最佳置换算法将页面1淘汰……依此类推，如图3-26所示。从图中可以看出釆用最佳置换算法时的情况。  
  
可以看到，发生缺页中断的次数为9，页面置换的次数为6。
</code></pre><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/202207251441696.png alt></p><h2 id=先进先出-fifo>先进先出 FIFO<a hidden class=anchor aria-hidden=true href=#先进先出-fifo>#</a></h2><p><strong>优先淘汰最早进入内存的页面，亦即在内存中驻留时间最久的页面。</strong></p><ul><li>该算法实现简单，只需把调入内存的页面根据先后次序链接成队列，设置一个指针总指向最早的页面。</li><li>但该算法与进程实际运行时的规律不适应，因为在进程中，有的页面经常被访问。</li></ul><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/202207251442187.png alt></p><pre tabindex=0><code>这里仍用上面的实例，釆用FIFO算法进行页面置换。进程访问页面2时，把最早进入内存的页面7换出。然后访问页面3时，再把2, 0, 1中最先进入内存的页换出。由图 3-27可以看出，利用FIFO算法时进行了 12次页面置换，比最佳置换算法正好多一倍。
</code></pre><p><strong>Belady 异常</strong></p><ul><li><strong>FIFO 算法还会产生当所分配的物理块数增大而页故障数不减反增的异常现象</strong>，这是由 Belady 于 1969 年发现，故称为 Belady 异常<ul><li>只有 FIFO 算法可能出现 Belady 异常，而 LRU 和 OPT 算法永远不会出现 Belady 异常。</li></ul></li></ul><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/202207251443084.png alt></p><h2 id=最近最久未使用-lru>最近最久未使用 LRU<a hidden class=anchor aria-hidden=true href=#最近最久未使用-lru>#</a></h2><p><strong>选择最近最长时间未访问过的页面予以淘汰，它认为过去一段时间内未访问过的页面，在最近的将来可能也不会被访问</strong>。</p><ul><li>该算法为每个页面设置一个访问字段，来记录页面自上次被访问以来所经历的时间，淘汰页面时选择现有页面中值最大的予以淘汰。</li></ul><pre tabindex=0><code>再对上面的实例釆用LRU算法进行页面置换，如图3-29所示。进程第一次对页面2访问时，将最近最久未被访问的页面7置换出去。然后访问页面3时，将最近最久未使用的页面1换出。
</code></pre><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/202207251443803.png alt></p><ul><li><p>在图 3-29 中，前 5 次置换的情况与最佳置换算法相同，但两种算法并无必然联系。</p><ul><li><strong>实际上，LRU 算法根据各页以前的情况，是“向前看”的</strong></li><li><strong>而最佳置换算法则根据各页以后的使用情况，是“向后看”的</strong>，所以 OPT 算法无法真正实现。</li></ul></li><li><p>LRU 性能较好，但需要寄存器和栈的硬件支持。</p></li><li><p>LRU 是堆栈类的算法。理论上可以证明，堆栈类算法不可能出现 Belady 异常。FIFO 算法基于队列实现，不是堆栈类算法。</p></li></ul><h2 id=时钟置换算法-clock>时钟置换算法 CLOCK<a hidden class=anchor aria-hidden=true href=#时钟置换算法-clock>#</a></h2><p><strong>LRU 算法的性能接近于 OPT,但是实现起来比较困难，且开销大；FIFO 算法实现简单，但性能差。所以操作系统的设计者尝试了很多算法，试图用比较小的开销接近 LRU 的性能，这类算法都是 CLOCK 算法的变体。</strong></p><p><strong>一个更好的办法是把所有的页面都保存在一个类似钟面的环形链表中,一个表针指向最老的页面</strong></p><ul><li>当发生缺页中断时，算法首先检查表指针指向的页面<ul><li><strong>如果它的 R 位是 0 就淘汰该页面</strong>，并把新的页面插入这个位置，然后把表针前移一个位置</li><li><strong>如果它的 R 位是 1 就清除 R 位，设置为 0，并把表针前移一个位置。</strong> 重复这个过程直到找到一个 R 位 0 的页面为止。</li></ul></li></ul><p><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/202208031548928.png alt></p><ul><li>简单的 CLOCK 算法是给每一帧关联一个附加位，称为使用位。当某一页首次装入主存时，该帧的使用位设置为 1;当该页随后再被访问到时，它的使用位也被置为 1。对于页替换算法，用于替换的候选帧集合看做一个循环缓冲区，并且有一个指针与之相关联。当某一页被替换时，该指针被设置成指向缓冲区中的下一帧。<ul><li>当需要替换一页时，操作系统扫描缓冲区，以查找使用位被置为 0 的一帧。每当遇到一个使用位为 1 的帧时，操作系统就将该位重新置为 0；如果在这个过程开始时，缓冲区中所有帧的使用位均为 0，则选择遇到的第一个帧替换；如果所有帧的使用位均为 1,则指针在缓冲区中完整地循环一周，把所有使用位都置为 0，并且停留在最初的位置上，替换该帧中的页。</li><li><strong>由于该算法循环地检查各页面的情况，故称为 CLOCK 算法，又称为最近未用(Not Recently Used, NRU)算法。</strong></li></ul></li></ul><p><strong>LRU 的各种变体算法——改进型CLOCK置换算法</strong></p><ul><li><p>CLOCK 算法的性能比较接近 LRU，而通过增加使用的位数目，可以使得 CLOCK 算法更加高效。在使用位的基础上再增加一个修改位，则得到改进型的 CLOCK 置换算法。这样，每一帧都处于以下四种情况之一：</p><ol><li>最近未被访问，也未被修改(u=0, m=0)。</li><li>最近被访问，但未被修改(u=1, m=0)。</li><li>最近未被访问，但被修改(u=0, m=1)。</li><li>最近被访问，被修改(u=1, m=1)。</li></ol></li><li><p>算法执行如下操作步骤：</p><ol><li>从指针的当前位置开始，扫描帧缓冲区。在这次扫描过程中，对使用位不做任何修改。选择遇到的第一个帧(u=0, m=0)用于替换。</li><li>如果第 1 步失败，则重新扫描，查找(u=0, m=1)的帧。选择遇到的第一个这样的帧用于替换。在这个扫描过程中，对每个跳过的帧，把它的使用位设置成 0。</li><li>如果第 2 步失败，指针将回到它的最初位置，并且集合中所有帧的使用位均为 0。重复第 1 步，并且如果有必要，重复第 2 步。这样将可以找到供替换的帧。</li></ol></li><li><p>改进型的 CLOCK 算法优于简单 CLOCK 算法之处在于替换时首选没有变化的页。由于修改过的页在被替换之前必须写回，因而这样做会节省时间。</p></li></ul><h1 id=页面分配策略>页面分配策略<a hidden class=anchor aria-hidden=true href=#页面分配策略>#</a></h1><h2 id=驻留集>驻留集<a hidden class=anchor aria-hidden=true href=#驻留集>#</a></h2><p>对于分页式的虚拟内存，在准备执行时，不需要也不可能把一个进程的所有页都读取到主存，<strong>因此，操作系统必须决定读取多少页</strong>。也就是说，<strong>给特定的进程分配多大的主存空间</strong>，这需要考虑以下几点：</p><ol><li>分配给一个进程的存储量越小，在任何时候驻留在主存中的进程数就越多，从而可以提高处理机的时间利用效率。</li><li>如果一个进程在主存中的页数过少，尽管有局部性原理，页错误率仍然会相对较高。</li><li>如果页数过多，由于局部性原理，给特定的进程分配更多的主存空间对该进程的错误率没有明显的影响。</li></ol><p><strong>三种驻留集大小分配策略</strong></p><ul><li><strong>固定分配局部置换。</strong><ul><li>它为每个进程分配一定数目的物理块，在整个运行期间都不改变。若进程在运行中发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后再调入需要的页面。</li><li>实现这种策略难以确定为每个进程应分配的物理块数目：太少会频繁出现缺页中断，太多又会使 CPU 和其他资源利用率下降。</li></ul></li><li><strong>可变分配全局置换</strong>。<ul><li>这是最易于实现的物理块分配和置换策略，为系统中的每个进程分配一定数目的物理块,操作系统自身也保持一个空闲物理块队列。</li><li>当某进程发生缺页时，系统从空闲物理块队列中取出一个物理块分配给该进程，并将欲调入的页装入其中</li></ul></li><li><strong>可变分配局部置换</strong>。<ul><li>它为每个进程分配一定数目的物理块，当某进程发生缺页时，只允许从该进程在内存的页面中选出一页换出，这样就不会影响其他进程的运行。</li><li>如果进程在运行中频繁地缺页，系统再为该进程分配若干物理块，直至该进程缺页率趋于适当程度； 反之，若进程在运行中缺页率特别低，则可适当减少分配给该进程的物理块。</li></ul></li></ul><h2 id=页面调入时机>页面调入时机<a hidden class=anchor aria-hidden=true href=#页面调入时机>#</a></h2><p>为确定系统将进程运行时所缺的页面调入内存的时机，可釆取以下两种调页策略：</p><ul><li><p><strong>预调页策略。</strong></p><ul><li>根据局部性原理，一次调入若干个相邻的页可能会比一次调入一页更高效。但如果调入的一批页面中大多数都未被访问，则又是低效的。</li><li>所以就需要釆用以预测为基础的预调页策略，将预计在不久之后便会被访问的页面预先调入内存。但目前预调页的成功率仅约 50%。故这种策略主要用于进程的首次调入时，由程序员指出应该先调入哪些页。</li></ul></li><li><p><strong>请求调页策略。</strong></p><ul><li>进程在运行中需要访问的页面不在内存而提出请求，由系统将所需页面调入内存。</li><li>由这种策略调入的页一定会被访问，且这种策略比较易于实现，故在目前的虚拟存储器中大多釆用此策略。它的缺点在于每次只调入一页，调入调出页面数多时会花费过多的 I/O 开销。</li></ul></li><li><p><em>Q：从何处调入页面？</em></p><ul><li>请求分页系统中的外存分为两部分：用于存放文件的文件区和用于存放对换页面的对换区。</li><li>对换区通常是釆用连续分配方式，而文件区釆用离散分配方式，故对换区的磁盘 I/O 速度比文件区的更快。这样从何处调入页面有三种情况：<ul><li><strong>系统拥有足够的对换区空间</strong>：可以全部从对换区调入所需页面，以提髙调页速度。为此，在进程运行前，需将与该进程有关的文件从文件区复制到对换区。</li><li><strong>系统缺少足够的对换区空间</strong>：凡不会被修改的文件都直接从文件区调入；而当换出这些页面时，由于它们未被修改而不必再将它们换出。但对于那些可能被修改的部分，在将它们换出时须调到对换区，以后需要时再从对换区调入。</li><li><strong>UNIX 方式</strong>：与进程有关的文件都放在文件区，故未运行过的页面，都应从文件区调入。曾经运行过但又被换出的页面，由于是被放在对换区，因此下次调入时应从对换区调入。进程请求的共享页面若被其他进程调入内存，则无需再从对换区调入。</li></ul></li></ul></li></ul><h1 id=抖动>抖动<a hidden class=anchor aria-hidden=true href=#抖动>#</a></h1><p><strong>在页面置换过程中的一种最糟糕的情形是，刚刚换出的页面马上又要换入主存，刚刚换入的页面马上就要换出主存，这种频繁的页面调度行为称为抖动，或颠簸。</strong></p><ul><li>如果一个进程在换页上用的时间多于执行时间，那么这个进程就在颠簸。</li><li>频繁的发生缺页中断（抖动），其主要原因是某个进程频繁访问的页面数目高于可用的物理页帧数目。<ul><li>虚拟内存技术可以在内存中保留更多的进程以提髙系统效率。在稳定状态，几乎主存的所有空间都被进程块占据，处理机和操作系统可以直接访问到尽可能多的进程。</li><li>但如果管理不当，处理机的大部分时间都将用于交换块，即请求调入页面的操作，而不是执行进程的指令，这就会大大降低系统效率。</li></ul></li></ul><h1 id=工作集>工作集<a hidden class=anchor aria-hidden=true href=#工作集>#</a></h1><p><strong>工作集（或驻留集）是指在某段时间间隔内，进程要访问的页面集合</strong>。</p><ul><li>经常被使用的页面需要在工作集中，而长期不被使用的页面要从工作集中被丢弃。为了防止系统出现抖动现象，需要选择合适的工作集大小。</li><li>工作集模型的原理是：<strong>让操作系统跟踪每个进程的工作集，并为进程分配大于其工作集的物理块。</strong><ul><li>如果还有空闲物理块，则可以再调一个进程到内存以增加多道程序数。</li><li>如果所有工作集之和增加以至于超过了可用物理块的总数，那么操作系统会暂停一个进程，将其页面调出并且将其物理块分配给其他进程，防止出现抖动现象。</li></ul></li></ul><p>正确选择工作集的大小，对存储器的利用率和系统吞吐量的提高，都将产生重要影响。</p><h1 id=小结>小结<a hidden class=anchor aria-hidden=true href=#小结>#</a></h1><ul><li><p>分页与分段的区别</p><ul><li><img loading=lazy src=https://raw.githubusercontent.com/CaesarYangs/MyPictureHotel/main/BasicImg/202207251500365.png alt></li></ul></li><li><p><strong>内部碎片与外部碎片🧩</strong></p><ul><li>重点在于理解浪费内存的区域叫做碎片，而内部和外部是相对于当前使用的分配结构来说的</li><li><strong>内部碎片</strong>：在一个分配结构块内产生的碎片。无法被其他进程或作业再次利用<ul><li>如固定分区，每块区域大小固定的。</li><li>如分页管理，每一页尽管大小很小，并且在有些 OS 中提供了不同的种类选择，但依旧是基本相同的固定大小。</li><li>如段页式，其本质还是将分段后的内存页面化存储。则与分页管理的存储本质完全相同</li></ul></li><li><strong>外部碎片</strong>：在分配结构之间的碎片。可以随着使用和优化被其他进程或碎片再次利用<ul><li>如动态分区管理，其所采用的最先适应，最佳适应，最坏适应，临近适应，就是为了更好地利用外部碎片而生的</li><li>如段式管理，每个段是动态不固定的，由当前的进程需求决定分配的大小。故和动态分区非常类似，会产生段间内存碎片，即外部碎片。</li></ul></li><li><em>THINK：后续的这些实现虚存的算法，是否是之前简单算法思想的延续？</em></li></ul></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=/tags/learning/>Learning</a></li><li><a href=/tags/notes/>Notes</a></li><li><a href=/tags/os/>OS</a></li></ul><nav class=paginav><a class=prev href=/post/tech/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/o4-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/><span class=title>« Prev</span><br><span>O4-文件系统</span></a>
<a class=next href=/post/tech/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/o1.5-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E7%95%8C%E9%9D%A2/><span class=title>Next »</span><br><span>O1.5-操作系统用户界面</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share O3-内存管理 on twitter" href="https://twitter.com/intent/tweet/?text=O3-%e5%86%85%e5%ad%98%e7%ae%a1%e7%90%86&url=%2fpost%2ftech%2f%25E6%2593%258D%25E4%25BD%259C%25E7%25B3%25BB%25E7%25BB%259F%25E7%25AC%2594%25E8%25AE%25B0%2fo3-%25E5%2586%2585%25E5%25AD%2598%25E7%25AE%25A1%25E7%2590%2586%2f&hashtags=Learning%2cNotes%2cOS"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share O3-内存管理 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=%2fpost%2ftech%2f%25E6%2593%258D%25E4%25BD%259C%25E7%25B3%25BB%25E7%25BB%259F%25E7%25AC%2594%25E8%25AE%25B0%2fo3-%25E5%2586%2585%25E5%25AD%2598%25E7%25AE%25A1%25E7%2590%2586%2f&title=O3-%e5%86%85%e5%ad%98%e7%ae%a1%e7%90%86&summary=O3-%e5%86%85%e5%ad%98%e7%ae%a1%e7%90%86&source=%2fpost%2ftech%2f%25E6%2593%258D%25E4%25BD%259C%25E7%25B3%25BB%25E7%25BB%259F%25E7%25AC%2594%25E8%25AE%25B0%2fo3-%25E5%2586%2585%25E5%25AD%2598%25E7%25AE%25A1%25E7%2590%2586%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share O3-内存管理 on reddit" href="https://reddit.com/submit?url=%2fpost%2ftech%2f%25E6%2593%258D%25E4%25BD%259C%25E7%25B3%25BB%25E7%25BB%259F%25E7%25AC%2594%25E8%25AE%25B0%2fo3-%25E5%2586%2585%25E5%25AD%2598%25E7%25AE%25A1%25E7%2590%2586%2f&title=O3-%e5%86%85%e5%ad%98%e7%ae%a1%e7%90%86"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share O3-内存管理 on facebook" href="https://facebook.com/sharer/sharer.php?u=%2fpost%2ftech%2f%25E6%2593%258D%25E4%25BD%259C%25E7%25B3%25BB%25E7%25BB%259F%25E7%25AC%2594%25E8%25AE%25B0%2fo3-%25E5%2586%2585%25E5%25AD%2598%25E7%25AE%25A1%25E7%2590%2586%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share O3-内存管理 on whatsapp" href="https://api.whatsapp.com/send?text=O3-%e5%86%85%e5%ad%98%e7%ae%a1%e7%90%86%20-%20%2fpost%2ftech%2f%25E6%2593%258D%25E4%25BD%259C%25E7%25B3%25BB%25E7%25BB%259F%25E7%25AC%2594%25E8%25AE%25B0%2fo3-%25E5%2586%2585%25E5%25AD%2598%25E7%25AE%25A1%25E7%2590%2586%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share O3-内存管理 on telegram" href="https://telegram.me/share/url?text=O3-%e5%86%85%e5%ad%98%e7%ae%a1%e7%90%86&url=%2fpost%2ftech%2f%25E6%2593%258D%25E4%25BD%259C%25E7%25B3%25BB%25E7%25BB%259F%25E7%25AC%2594%25E8%25AE%25B0%2fo3-%25E5%2586%2585%25E5%25AD%2598%25E7%25AE%25A1%25E7%2590%2586%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2022 <a href>Caesar's Paperbox</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>